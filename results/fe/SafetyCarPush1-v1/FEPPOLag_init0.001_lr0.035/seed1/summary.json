{
    "Loss/Loss_cost_critic": 0.17880937457084656,
    "Loss/Loss_cost_critic/Delta": 0.10493548214435576,
    "Loss/Loss_pi": -0.003669386962428689,
    "Loss/Loss_pi/Delta": 0.0012275364715605974,
    "Loss/Loss_reward_critic": 0.006624529138207436,
    "Loss/Loss_reward_critic/Delta": -0.0004917341284453869,
    "Metrics/EpCost": 2.940000057220459,
    "Metrics/EpLen": 1000,
    "Metrics/EpRet": -0.06508687883615494,
    "Metrics/LagrangeMultiplier": 2.5679283142089844,
    "Metrics/LagrangeMultiplier/Max": 2.5679283142089844,
    "Metrics/LagrangeMultiplier/Min": 2.5679283142089844,
    "Metrics/LagrangeMultiplier/Std": 0,
    "Time/Epoch": 137.371337890625,
    "Time/FPS": 145.59078979492188,
    "Time/Rollout": 72.94587707519531,
    "Time/Total": 11999.4404296875,
    "Time/Update": 64.4254150390625,
    "TotalEnvSteps": 2000000,
    "Train/Entropy": 0.3288417458534241,
    "Train/Epoch": 99,
    "Train/KL": 0.003986838273704052,
    "Train/LR": 0,
    "Train/PolicyRatio": 1.00016188621521,
    "Train/PolicyRatio/Max": 1.00016188621521,
    "Train/PolicyRatio/Min": 1.00016188621521,
    "Train/PolicyRatio/Std": 0.006794855464249849,
    "Train/PolicyStd": 0.3362034857273102,
    "Train/StopIter": 40,
    "Value/Adv": -0.15886621177196503,
    "Value/cost": 0.3317796289920807,
    "Value/reward": -0.016890637576580048,
    "_runtime": 12006.01774974,
    "_step": 100,
    "_timestamp": 1746910574.44981,
    "_wandb": {
        "runtime": 12006
    }
}