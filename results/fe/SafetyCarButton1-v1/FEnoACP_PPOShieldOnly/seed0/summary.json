{
    "Loss/Loss_cost_critic": 7.148884296417236,
    "Loss/Loss_cost_critic/Delta": -5.638086795806885,
    "Loss/Loss_pi": -0.8992469906806946,
    "Loss/Loss_pi/Delta": -1.2104170322418213,
    "Loss/Loss_reward_critic": 0.05328839644789696,
    "Loss/Loss_reward_critic/Delta": -0.013688836246728895,
    "Metrics/EpCost": 39.220001220703125,
    "Metrics/EpLen": 1000,
    "Metrics/EpRet": 10.30440902709961,
    "Metrics/LagrangeMultiplier": 3.27738356590271,
    "Metrics/LagrangeMultiplier/Max": 3.27738356590271,
    "Metrics/LagrangeMultiplier/Min": 3.27738356590271,
    "Metrics/LagrangeMultiplier/Std": 0,
    "Safety/EpCostShield": 61.70000076293945,
    "Safety/ShieldLagrangeMultiplier": 3.16329288482666,
    "Safety/ShieldLagrangeMultiplier/Max": 3.16329288482666,
    "Safety/ShieldLagrangeMultiplier/Min": 3.16329288482666,
    "Safety/ShieldLagrangeMultiplier/Std": 0,
    "Safety/shield_adv_c": "NaN",
    "Safety/shield_violation": 12.36516284942627,
    "Time/Epoch": 185.64801025390625,
    "Time/FPS": 107.7307586669922,
    "Time/Rollout": 91.32095336914062,
    "Time/Total": 16741.83203125,
    "Time/Update": 94.32699584960938,
    "TotalEnvSteps": 2000000,
    "Train/Entropy": 0.05833754688501358,
    "Train/Epoch": 99,
    "Train/KL": 0.00384992896579206,
    "Train/LR": 0,
    "Train/PolicyRatio": 1.0027447938919067,
    "Train/PolicyRatio/Max": 1.0027447938919067,
    "Train/PolicyRatio/Min": 1.0027447938919067,
    "Train/PolicyRatio/Std": 0.006669699680060148,
    "Train/PolicyStd": 0.2574392259120941,
    "Train/StopIter": 40,
    "Value/Adv": -0.033793263137340546,
    "Value/cost": 4.548245429992676,
    "Value/reward": 1.1934990882873535,
    "_runtime": 16743.532128197,
    "_step": 100,
    "_timestamp": 1746638209.8038454,
    "_wandb": {
        "runtime": 16743
    }
}