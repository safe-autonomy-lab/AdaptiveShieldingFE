{
    "Loss/Loss_cost_critic": 3.676786422729492,
    "Loss/Loss_cost_critic/Delta": -0.6058225631713867,
    "Loss/Loss_pi": -0.1256498396396637,
    "Loss/Loss_pi/Delta": 0.15126731991767883,
    "Loss/Loss_reward_critic": 0.05133910849690437,
    "Loss/Loss_reward_critic/Delta": -0.01650632545351982,
    "Metrics/EpCost": 20.93000030517578,
    "Metrics/EpLen": 1000,
    "Metrics/EpRet": 7.432440280914307,
    "Metrics/LagrangeMultiplier": 2.8850619792938232,
    "Metrics/LagrangeMultiplier/Max": 2.8850619792938232,
    "Metrics/LagrangeMultiplier/Min": 2.8850619792938232,
    "Metrics/LagrangeMultiplier/Std": 0,
    "Safety/EpCostShield": 63.900001525878906,
    "Safety/ShieldLagrangeMultiplier": 2.92204213142395,
    "Safety/ShieldLagrangeMultiplier/Max": 2.92204213142395,
    "Safety/ShieldLagrangeMultiplier/Min": 2.92204213142395,
    "Safety/ShieldLagrangeMultiplier/Std": 0,
    "Safety/shield_adv_c": "NaN",
    "Safety/shield_violation": 6.4719343185424805,
    "Time/Epoch": 257.7154846191406,
    "Time/FPS": 77.6049575805664,
    "Time/Rollout": 112.43965911865234,
    "Time/Total": 22852.826171875,
    "Time/Update": 145.27577209472656,
    "TotalEnvSteps": 2000000,
    "Train/Entropy": -0.05678858980536461,
    "Train/Epoch": 99,
    "Train/KL": 0.004159609321504831,
    "Train/LR": 0,
    "Train/PolicyRatio": 1.0028120279312134,
    "Train/PolicyRatio/Max": 1.0028120279312134,
    "Train/PolicyRatio/Min": 1.0028120279312134,
    "Train/PolicyRatio/Std": 0.007198058068752289,
    "Train/PolicyStd": 0.22929055988788605,
    "Train/StopIter": 40,
    "Value/Adv": -0.10878322273492812,
    "Value/cost": 2.2228071689605713,
    "Value/reward": 0.9181835651397704,
    "_runtime": 22854.314667493,
    "_step": 100,
    "_timestamp": 1746592497.9214044,
    "_wandb": {
        "runtime": 22854
    }
}