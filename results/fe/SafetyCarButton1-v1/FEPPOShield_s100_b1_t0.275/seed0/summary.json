{
    "Loss/Loss_cost_critic": 4.626852512359619,
    "Loss/Loss_cost_critic/Delta": -0.693242073059082,
    "Loss/Loss_pi": -0.41240331530570984,
    "Loss/Loss_pi/Delta": 0.014136552810668944,
    "Loss/Loss_reward_critic": 0.03484924137592316,
    "Loss/Loss_reward_critic/Delta": 0.0006028003990650177,
    "Metrics/EpCost": 25.280000686645508,
    "Metrics/EpLen": 1000,
    "Metrics/EpRet": 4.839077949523926,
    "Metrics/LagrangeMultiplier": 3.05218505859375,
    "Metrics/LagrangeMultiplier/Max": 3.05218505859375,
    "Metrics/LagrangeMultiplier/Min": 3.05218505859375,
    "Metrics/LagrangeMultiplier/Std": 0,
    "Safety/EpCostShield": 39.900001525878906,
    "Safety/ShieldLagrangeMultiplier": 2.971024751663208,
    "Safety/ShieldLagrangeMultiplier/Max": 2.971024751663208,
    "Safety/ShieldLagrangeMultiplier/Min": 2.971024751663208,
    "Safety/ShieldLagrangeMultiplier/Std": 0,
    "Safety/shield_adv_c": "NaN",
    "Safety/shield_violation": 6.905928134918213,
    "Time/Epoch": 217.2151641845703,
    "Time/FPS": 92.07460021972656,
    "Time/Rollout": 107.90127563476562,
    "Time/Total": 19585.44140625,
    "Time/Update": 109.31381225585938,
    "TotalEnvSteps": 2000000,
    "Train/Entropy": 0.28968459367752075,
    "Train/Epoch": 99,
    "Train/KL": 0.003818139899522066,
    "Train/LR": 0,
    "Train/PolicyRatio": 1.001801609992981,
    "Train/PolicyRatio/Max": 1.0018017292022705,
    "Train/PolicyRatio/Min": 1.0018017292022705,
    "Train/PolicyRatio/Std": 0.007103119045495987,
    "Train/PolicyStd": 0.3252854347229004,
    "Train/StopIter": 40,
    "Value/Adv": 0.1138322651386261,
    "Value/cost": 3.104455947875977,
    "Value/reward": 0.6068544387817383,
    "_runtime": 19586.660701031,
    "_step": 100,
    "_timestamp": 1746549747.0070348,
    "_wandb": {
        "runtime": 19586
    }
}