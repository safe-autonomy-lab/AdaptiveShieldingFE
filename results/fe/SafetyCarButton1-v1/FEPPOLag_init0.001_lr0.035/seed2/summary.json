{
    "Loss/Loss_cost_critic": 2.0072784423828125,
    "Loss/Loss_cost_critic/Delta": 0.11602520942687988,
    "Loss/Loss_pi": -0.016413124278187752,
    "Loss/Loss_pi/Delta": 0.013021159917116163,
    "Loss/Loss_reward_critic": 0.06374496966600418,
    "Loss/Loss_reward_critic/Delta": -0.015834704041481018,
    "Metrics/EpCost": 44.400001525878906,
    "Metrics/EpLen": 1000,
    "Metrics/EpRet": 10.010028839111328,
    "Metrics/LagrangeMultiplier": 3.1600961685180664,
    "Metrics/LagrangeMultiplier/Max": 3.1600961685180664,
    "Metrics/LagrangeMultiplier/Min": 3.1600961685180664,
    "Metrics/LagrangeMultiplier/Std": 0,
    "Time/Epoch": 136.1876220703125,
    "Time/FPS": 146.85623168945312,
    "Time/Rollout": 75.71096801757812,
    "Time/Total": 12222.390625,
    "Time/Update": 60.4765625,
    "TotalEnvSteps": 2000000,
    "Train/Entropy": 0.4492664039134979,
    "Train/Epoch": 99,
    "Train/KL": 0.003453613957390189,
    "Train/LR": 0,
    "Train/PolicyRatio": 1.0005221366882324,
    "Train/PolicyRatio/Max": 1.0005221366882324,
    "Train/PolicyRatio/Min": 1.0005221366882324,
    "Train/PolicyRatio/Std": 0.006166530307382345,
    "Train/PolicyStd": 0.3792074620723725,
    "Train/StopIter": 40,
    "Value/Adv": 0.0778491199016571,
    "Value/cost": 3.1520469188690186,
    "Value/reward": 1.1459226608276367,
    "_runtime": 12224.265487449,
    "_step": 100,
    "_timestamp": 1746910813.9006512,
    "_wandb": {
        "runtime": 12224
    }
}