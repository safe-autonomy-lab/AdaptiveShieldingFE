{
    "Loss/Loss_cost_critic": 1.615417242050171,
    "Loss/Loss_cost_critic/Delta": -0.9339163303375244,
    "Loss/Loss_pi": 0.02828359603881836,
    "Loss/Loss_pi/Delta": 0.024476456455886364,
    "Loss/Loss_reward_critic": 0.10456249117851256,
    "Loss/Loss_reward_critic/Delta": 0.018928609788417816,
    "Metrics/EpCost": 3.5399999618530273,
    "Metrics/EpLen": 500,
    "Metrics/EpRet": 12.074767112731934,
    "Metrics/LagrangeMultiplier": 0.8934388160705566,
    "Metrics/LagrangeMultiplier/Max": 0.8934388160705566,
    "Metrics/LagrangeMultiplier/Min": 0.8934388160705566,
    "Metrics/LagrangeMultiplier/Std": 0,
    "Safety/EpCostShield": 8.324999809265137,
    "Safety/ShieldLagrangeMultiplier": 1.1581639051437378,
    "Safety/ShieldLagrangeMultiplier/Max": 1.1581639051437378,
    "Safety/ShieldLagrangeMultiplier/Min": 1.1581639051437378,
    "Safety/ShieldLagrangeMultiplier/Std": 0,
    "Safety/shield_adv_c": "NaN",
    "Safety/shield_violation": 1.12029767036438,
    "Time/Epoch": 184.04624938964844,
    "Time/FPS": 108.6683349609375,
    "Time/Rollout": 89.83246612548828,
    "Time/Total": 17497.87109375,
    "Time/Update": 94.21372985839844,
    "TotalEnvSteps": 2000000,
    "Train/Entropy": 0.4615516662597656,
    "Train/Epoch": 99,
    "Train/KL": 0.00414283899590373,
    "Train/LR": 0,
    "Train/PolicyRatio": 1.0003254413604736,
    "Train/PolicyRatio/Max": 1.0003254413604736,
    "Train/PolicyRatio/Min": 1.0003254413604736,
    "Train/PolicyRatio/Std": 0.007591158151626587,
    "Train/PolicyStd": 0.38947737216949463,
    "Train/StopIter": 40,
    "Value/Adv": -0.13762825727462769,
    "Value/cost": 0.16003839671611786,
    "Value/reward": 2.322965145111084,
    "_runtime": 17499.451045739,
    "_step": 100,
    "_timestamp": 1746639528.6304235,
    "_wandb": {
        "runtime": 17499
    }
}