{
    "Loss/Loss_cost_critic": 1.564682126045227,
    "Loss/Loss_cost_critic/Delta": 0.0015425682067871094,
    "Loss/Loss_pi": -0.007353871129453182,
    "Loss/Loss_pi/Delta": 0.005218288861215115,
    "Loss/Loss_reward_critic": 0.08739554136991501,
    "Loss/Loss_reward_critic/Delta": 0.003031313419342041,
    "Metrics/EpCost": 9.18000030517578,
    "Metrics/EpLen": 500,
    "Metrics/EpRet": 11.52966022491455,
    "Metrics/LagrangeMultiplier": 1.629281759262085,
    "Metrics/LagrangeMultiplier/Max": 1.629281759262085,
    "Metrics/LagrangeMultiplier/Min": 1.629281759262085,
    "Metrics/LagrangeMultiplier/Std": 0,
    "Time/Epoch": 143.21376037597656,
    "Time/FPS": 139.65139770507812,
    "Time/Rollout": 77.04800415039062,
    "Time/Total": 13436.380859375,
    "Time/Update": 66.16568756103516,
    "TotalEnvSteps": 2000000,
    "Train/Entropy": 0.15593910217285156,
    "Train/Epoch": 99,
    "Train/KL": 0.004300838336348534,
    "Train/LR": 0,
    "Train/PolicyRatio": 1.0009896755218506,
    "Train/PolicyRatio/Max": 1.0009896755218506,
    "Train/PolicyRatio/Min": 1.0009896755218506,
    "Train/PolicyRatio/Std": 0.007435295730829239,
    "Train/PolicyStd": 0.2835456132888794,
    "Train/StopIter": 40,
    "Value/Adv": -0.09514772146940231,
    "Value/cost": 1.392653465270996,
    "Value/reward": 2.3394086360931396,
    "_runtime": 13439.719412276,
    "_step": 100,
    "_timestamp": 1746912011.494787,
    "_wandb": {
        "runtime": 13439
    }
}