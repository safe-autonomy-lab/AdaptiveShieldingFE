{
    "Loss/Loss_cost_critic": 2.982158660888672,
    "Loss/Loss_cost_critic/Delta": 0.4290328025817871,
    "Loss/Loss_pi": -0.00885795708745718,
    "Loss/Loss_pi/Delta": 0.0027240710332989693,
    "Loss/Loss_reward_critic": 0.14820340275764465,
    "Loss/Loss_reward_critic/Delta": 0.03708050400018692,
    "Metrics/EpCost": 16.979999542236328,
    "Metrics/EpLen": 500,
    "Metrics/EpRet": 13.8125,
    "Metrics/LagrangeMultiplier": 1.216209888458252,
    "Metrics/LagrangeMultiplier/Max": 1.216209888458252,
    "Metrics/LagrangeMultiplier/Min": 1.216209888458252,
    "Metrics/LagrangeMultiplier/Std": 0,
    "Time/Epoch": 166.89955139160156,
    "Time/FPS": 119.83255767822266,
    "Time/Rollout": 88.42789459228516,
    "Time/Total": 15786.2900390625,
    "Time/Update": 78.47160339355469,
    "TotalEnvSteps": 2000000,
    "Train/Entropy": 0.16219371557235718,
    "Train/Epoch": 99,
    "Train/KL": 0.003906986676156521,
    "Train/LR": 0,
    "Train/PolicyRatio": 1.0008567571640017,
    "Train/PolicyRatio/Max": 1.0008567571640017,
    "Train/PolicyRatio/Min": 1.0008567571640017,
    "Train/PolicyRatio/Std": 0.0070692431181669235,
    "Train/PolicyStd": 0.28690317273139954,
    "Train/StopIter": 40,
    "Value/Adv": 0.07384270429611206,
    "Value/cost": 1.9974273443222048,
    "Value/reward": 2.7944555282592773,
    "_runtime": 15787.378427987,
    "_step": 100,
    "_timestamp": 1746914376.3807108,
    "_wandb": {
        "runtime": 15787
    }
}