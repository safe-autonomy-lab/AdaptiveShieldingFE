{
    "Loss/Loss_cost_critic": 2.127260208129883,
    "Loss/Loss_cost_critic/Delta": -4.174017429351807,
    "Loss/Loss_pi": -0.023869691416621208,
    "Loss/Loss_pi/Delta": -0.09622848592698574,
    "Loss/Loss_reward_critic": 0.07801241427659988,
    "Loss/Loss_reward_critic/Delta": 0.0021929070353507996,
    "Metrics/EpCost": 3.259999990463257,
    "Metrics/EpLen": 500,
    "Metrics/EpRet": 10.24227809906006,
    "Metrics/LagrangeMultiplier": 1.1315414905548096,
    "Metrics/LagrangeMultiplier/Max": 1.1315414905548096,
    "Metrics/LagrangeMultiplier/Min": 1.1315414905548096,
    "Metrics/LagrangeMultiplier/Std": 0,
    "Safety/EpCostShield": 3.950000047683716,
    "Safety/ShieldLagrangeMultiplier": 1.365628719329834,
    "Safety/ShieldLagrangeMultiplier/Max": 1.365628719329834,
    "Safety/ShieldLagrangeMultiplier/Min": 1.365628719329834,
    "Safety/ShieldLagrangeMultiplier/Std": 0,
    "Safety/shield_adv_c": "NaN",
    "Safety/shield_violation": 1.1432684659957886,
    "Time/Epoch": 243.2248077392578,
    "Time/FPS": 82.22845458984375,
    "Time/Rollout": 98.24710845947266,
    "Time/Total": 22218.037109375,
    "Time/Update": 144.97763061523438,
    "TotalEnvSteps": 2000000,
    "Train/Entropy": 0.6889653205871582,
    "Train/Epoch": 99,
    "Train/KL": 0.003947588615119457,
    "Train/LR": 0,
    "Train/PolicyRatio": 1.0002450942993164,
    "Train/PolicyRatio/Max": 1.0002450942993164,
    "Train/PolicyRatio/Min": 1.0002450942993164,
    "Train/PolicyRatio/Std": 0.006867981981486082,
    "Train/PolicyStd": 0.48424193263053894,
    "Train/StopIter": 40,
    "Value/Adv": -0.00021663308143615723,
    "Value/cost": 0.46516352891922,
    "Value/reward": 2.088233709335327,
    "_runtime": 22223.430388363,
    "_step": 100,
    "_timestamp": 1747272500.639733,
    "_wandb": {
        "runtime": 22223
    }
}