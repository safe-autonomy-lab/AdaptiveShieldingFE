{
    "Loss/Loss_cost_critic": 1.374535083770752,
    "Loss/Loss_cost_critic/Delta": 0.5149720907211304,
    "Loss/Loss_pi": -0.011614017188549042,
    "Loss/Loss_pi/Delta": -0.000939616933465004,
    "Loss/Loss_reward_critic": 0.08752137422561646,
    "Loss/Loss_reward_critic/Delta": 0.019399084150791168,
    "Metrics/EpCost": 23.90999984741211,
    "Metrics/EpLen": 1000,
    "Metrics/EpRet": 12.231907844543455,
    "Metrics/LagrangeMultiplier": 2.878861665725708,
    "Metrics/LagrangeMultiplier/Max": 2.878861665725708,
    "Metrics/LagrangeMultiplier/Min": 2.878861665725708,
    "Metrics/LagrangeMultiplier/Std": 0,
    "Time/Epoch": 178.6397247314453,
    "Time/FPS": 111.95718383789062,
    "Time/Rollout": 77.74360656738281,
    "Time/Total": 17562.123046875,
    "Time/Update": 100.89605712890624,
    "TotalEnvSteps": 2000000,
    "Train/Entropy": 0.6789779663085938,
    "Train/Epoch": 99,
    "Train/KL": 0.00371820735745132,
    "Train/LR": 0,
    "Train/PolicyRatio": 0.9997109174728394,
    "Train/PolicyRatio/Max": 0.9997109174728394,
    "Train/PolicyRatio/Min": 0.9997109174728394,
    "Train/PolicyRatio/Std": 0.007262311410158873,
    "Train/PolicyStd": 0.4788488745689392,
    "Train/StopIter": 40,
    "Value/Adv": -0.15717118978500366,
    "Value/cost": 3.379231214523315,
    "Value/reward": 1.4849886894226074,
    "_runtime": 17563.634204936,
    "_step": 100,
    "_timestamp": 1746916155.0743792,
    "_wandb": {
        "runtime": 17563
    }
}