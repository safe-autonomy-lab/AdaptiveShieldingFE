{
    "Loss/Loss_cost_critic": 7.895370483398437,
    "Loss/Loss_cost_critic/Delta": 3.5866951942443848,
    "Loss/Loss_pi": 0.048669811338186264,
    "Loss/Loss_pi/Delta": 0.42951759323477745,
    "Loss/Loss_reward_critic": 0.048637352883815765,
    "Loss/Loss_reward_critic/Delta": 0.0092100128531456,
    "Metrics/EpCost": 20.56999969482422,
    "Metrics/EpLen": 1000,
    "Metrics/EpRet": 4.980869770050049,
    "Metrics/LagrangeMultiplier": 2.6391966342926025,
    "Metrics/LagrangeMultiplier/Max": 2.6391966342926025,
    "Metrics/LagrangeMultiplier/Min": 2.6391966342926025,
    "Metrics/LagrangeMultiplier/Std": 0,
    "Safety/EpCostShield": 96.0999984741211,
    "Safety/ShieldLagrangeMultiplier": 2.638258218765259,
    "Safety/ShieldLagrangeMultiplier/Max": 2.638258218765259,
    "Safety/ShieldLagrangeMultiplier/Min": 2.638258218765259,
    "Safety/ShieldLagrangeMultiplier/Std": 0,
    "Safety/shield_adv_c": "NaN",
    "Safety/shield_violation": 7.984560966491699,
    "Time/Epoch": 256.3907470703125,
    "Time/FPS": 78.00593566894531,
    "Time/Rollout": 110.45256805419922,
    "Time/Total": 26243.794921875,
    "Time/Update": 145.9381103515625,
    "TotalEnvSteps": 2000000,
    "Train/Entropy": 0.1384279727935791,
    "Train/Epoch": 99,
    "Train/KL": 0.004493597894906998,
    "Train/LR": 0,
    "Train/PolicyRatio": 0.9990938305854796,
    "Train/PolicyRatio/Max": 0.9990938305854796,
    "Train/PolicyRatio/Min": 0.9990938305854796,
    "Train/PolicyRatio/Std": 0.007325740531086922,
    "Train/PolicyStd": 0.28071609139442444,
    "Train/StopIter": 40,
    "Value/Adv": -0.19250476360321045,
    "Value/cost": 2.6956067085266113,
    "Value/reward": 0.7924439311027527,
    "_runtime": 26246.251912089,
    "_step": 100,
    "_timestamp": 1746640493.5938425,
    "_wandb": {
        "runtime": 26246
    }
}