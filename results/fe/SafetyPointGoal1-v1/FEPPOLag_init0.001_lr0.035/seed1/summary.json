{
    "Loss/Loss_cost_critic": 1.0056647062301636,
    "Loss/Loss_cost_critic/Delta": -0.5767439603805542,
    "Loss/Loss_pi": -0.004502099473029375,
    "Loss/Loss_pi/Delta": 0.00478993309661746,
    "Loss/Loss_reward_critic": 0.03864087164402008,
    "Loss/Loss_reward_critic/Delta": 0.0016427412629127502,
    "Metrics/EpCost": 23.59000015258789,
    "Metrics/EpLen": 1000,
    "Metrics/EpRet": 17.482114791870117,
    "Metrics/LagrangeMultiplier": 3.0366954803466797,
    "Metrics/LagrangeMultiplier/Max": 3.0366954803466797,
    "Metrics/LagrangeMultiplier/Min": 3.0366954803466797,
    "Metrics/LagrangeMultiplier/Std": 0,
    "Time/Epoch": 129.60401916503906,
    "Time/FPS": 154.31619262695312,
    "Time/Rollout": 68.8021011352539,
    "Time/Total": 12964.896484375,
    "Time/Update": 60.801856994628906,
    "TotalEnvSteps": 2000000,
    "Train/Entropy": 0.7743635177612305,
    "Train/Epoch": 99,
    "Train/KL": 0.003069410566240549,
    "Train/LR": 0,
    "Train/PolicyRatio": 1.0001801252365112,
    "Train/PolicyRatio/Max": 1.0001801252365112,
    "Train/PolicyRatio/Min": 1.0001801252365112,
    "Train/PolicyRatio/Std": 0.006274035200476646,
    "Train/PolicyStd": 0.5263693928718567,
    "Train/StopIter": 40,
    "Value/Adv": -0.12683850526809692,
    "Value/cost": 3.2612104415893555,
    "Value/reward": 1.7760992050170898,
    "_runtime": 12966.989998844,
    "_step": 100,
    "_timestamp": 1746911543.241799,
    "_wandb": {
        "runtime": 12966
    }
}