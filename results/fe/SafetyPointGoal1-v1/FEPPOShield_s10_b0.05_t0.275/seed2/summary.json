{
    "Loss/Loss_cost_critic": 4.0744194984436035,
    "Loss/Loss_cost_critic/Delta": -0.030292987823486328,
    "Loss/Loss_pi": 0.0457652322947979,
    "Loss/Loss_pi/Delta": 0.16851699724793434,
    "Loss/Loss_reward_critic": 0.0542299784719944,
    "Loss/Loss_reward_critic/Delta": 0.011193253099918364,
    "Metrics/EpCost": 13.649999618530272,
    "Metrics/EpLen": 1000,
    "Metrics/EpRet": 10.397939682006836,
    "Metrics/LagrangeMultiplier": 2.685586929321289,
    "Metrics/LagrangeMultiplier/Max": 2.685586929321289,
    "Metrics/LagrangeMultiplier/Min": 2.685586929321289,
    "Metrics/LagrangeMultiplier/Std": 0,
    "Safety/EpCostShield": 38.900001525878906,
    "Safety/ShieldLagrangeMultiplier": 2.723740339279175,
    "Safety/ShieldLagrangeMultiplier/Max": 2.723740339279175,
    "Safety/ShieldLagrangeMultiplier/Min": 2.723740339279175,
    "Safety/ShieldLagrangeMultiplier/Std": 0,
    "Safety/shield_adv_c": "NaN",
    "Safety/shield_violation": 2.9024906158447266,
    "Time/Epoch": 229.62237548828125,
    "Time/FPS": 87.09952545166016,
    "Time/Rollout": 89.53877258300781,
    "Time/Total": 23897.779296875,
    "Time/Update": 140.08351135253906,
    "TotalEnvSteps": 2000000,
    "Train/Entropy": 0.15585996210575104,
    "Train/Epoch": 99,
    "Train/KL": 0.004409819841384888,
    "Train/LR": 0,
    "Train/PolicyRatio": 1.0005909204483032,
    "Train/PolicyRatio/Max": 1.0005909204483032,
    "Train/PolicyRatio/Min": 1.0005909204483032,
    "Train/PolicyRatio/Std": 0.007065614685416222,
    "Train/PolicyStd": 0.2862328886985779,
    "Train/StopIter": 40,
    "Value/Adv": -0.09621678292751312,
    "Value/cost": 1.7364623546600342,
    "Value/reward": 1.214047908782959,
    "_runtime": 23900.151434869,
    "_step": 100,
    "_timestamp": 1746567791.3702886,
    "_wandb": {
        "runtime": 23900
    }
}