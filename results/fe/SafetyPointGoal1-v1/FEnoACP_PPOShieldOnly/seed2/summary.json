{
    "Loss/Loss_cost_critic": 6.260778427124023,
    "Loss/Loss_cost_critic/Delta": -2.6192808151245117,
    "Loss/Loss_pi": -0.30227288603782654,
    "Loss/Loss_pi/Delta": -0.06690153479576111,
    "Loss/Loss_reward_critic": 0.05032302439212799,
    "Loss/Loss_reward_critic/Delta": -0.0003739558160305023,
    "Metrics/EpCost": 24.34000015258789,
    "Metrics/EpLen": 1000,
    "Metrics/EpRet": 15.38238525390625,
    "Metrics/LagrangeMultiplier": 2.920305013656616,
    "Metrics/LagrangeMultiplier/Max": 2.920305013656616,
    "Metrics/LagrangeMultiplier/Min": 2.920305013656616,
    "Metrics/LagrangeMultiplier/Std": 0,
    "Safety/EpCostShield": 45.04999923706055,
    "Safety/ShieldLagrangeMultiplier": 2.942250967025757,
    "Safety/ShieldLagrangeMultiplier/Max": 2.942250967025757,
    "Safety/ShieldLagrangeMultiplier/Min": 2.942250967025757,
    "Safety/ShieldLagrangeMultiplier/Std": 0,
    "Safety/shield_adv_c": "NaN",
    "Safety/shield_violation": 6.3189592361450195,
    "Time/Epoch": 176.48838806152344,
    "Time/FPS": 113.3218994140625,
    "Time/Rollout": 82.68477630615234,
    "Time/Total": 18405.19921875,
    "Time/Update": 93.80355072021484,
    "TotalEnvSteps": 2000000,
    "Train/Entropy": 0.0029732994735240936,
    "Train/Epoch": 99,
    "Train/KL": 0.003298165742307902,
    "Train/LR": 0,
    "Train/PolicyRatio": 1.0008424520492554,
    "Train/PolicyRatio/Max": 1.0008424520492554,
    "Train/PolicyRatio/Min": 1.0008424520492554,
    "Train/PolicyRatio/Std": 0.006052811164408922,
    "Train/PolicyStd": 0.24269840121269223,
    "Train/StopIter": 40,
    "Value/Adv": -0.037294477224349976,
    "Value/cost": 3.3986563682556152,
    "Value/reward": 1.548673391342163,
    "_runtime": 18406.461433668,
    "_step": 100,
    "_timestamp": 1746632369.704238,
    "_wandb": {
        "runtime": 18406
    }
}