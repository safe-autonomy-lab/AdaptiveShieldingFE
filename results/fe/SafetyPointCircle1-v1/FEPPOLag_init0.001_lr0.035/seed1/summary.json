{
    "Loss/Loss_cost_critic": 1.3287323713302612,
    "Loss/Loss_cost_critic/Delta": 0.19455456733703613,
    "Loss/Loss_pi": -0.0023052264004945755,
    "Loss/Loss_pi/Delta": 0.0002926061861217022,
    "Loss/Loss_reward_critic": 0.2162284255027771,
    "Loss/Loss_reward_critic/Delta": 0.008253052830696106,
    "Metrics/EpCost": 7.380000114440918,
    "Metrics/EpLen": 500,
    "Metrics/EpRet": 33.518699645996094,
    "Metrics/LagrangeMultiplier": 1.2509338855743408,
    "Metrics/LagrangeMultiplier/Max": 1.2509338855743408,
    "Metrics/LagrangeMultiplier/Min": 1.2509338855743408,
    "Metrics/LagrangeMultiplier/Std": 0,
    "Time/Epoch": 182.3795623779297,
    "Time/FPS": 109.66141510009766,
    "Time/Rollout": 85.7455825805664,
    "Time/Total": 18207.642578125,
    "Time/Update": 96.63388061523438,
    "TotalEnvSteps": 2000000,
    "Train/Entropy": 0.5472154021263123,
    "Train/Epoch": 99,
    "Train/KL": 0.003176553873345256,
    "Train/LR": 0,
    "Train/PolicyRatio": 1.000451683998108,
    "Train/PolicyRatio/Max": 1.0004518032073977,
    "Train/PolicyRatio/Min": 1.0004518032073977,
    "Train/PolicyRatio/Std": 0.006152688525617123,
    "Train/PolicyStd": 0.42034053802490234,
    "Train/StopIter": 40,
    "Value/Adv": 0.21590915322303772,
    "Value/cost": 1.0100198984146118,
    "Value/reward": 6.332117080688477,
    "_runtime": 18209.786918341,
    "_step": 100,
    "_timestamp": 1746916805.300468,
    "_wandb": {
        "runtime": 18209
    }
}