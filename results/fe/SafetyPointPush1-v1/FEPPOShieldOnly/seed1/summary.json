{
    "Loss/Loss_cost_critic": 2.25783371925354,
    "Loss/Loss_cost_critic/Delta": -0.49878573417663574,
    "Loss/Loss_pi": 0.189202144742012,
    "Loss/Loss_pi/Delta": 0.5462352484464645,
    "Loss/Loss_reward_critic": 0.004818962886929512,
    "Loss/Loss_reward_critic/Delta": -0.0008337404578924179,
    "Metrics/EpCost": 12.239999771118164,
    "Metrics/EpLen": 1000,
    "Metrics/EpRet": 0.023516768589615825,
    "Metrics/LagrangeMultiplier": 3.4218783378601074,
    "Metrics/LagrangeMultiplier/Max": 3.4218783378601074,
    "Metrics/LagrangeMultiplier/Min": 3.4218783378601074,
    "Metrics/LagrangeMultiplier/Std": 0,
    "Safety/EpCostShield": 61.20000076293945,
    "Safety/ShieldLagrangeMultiplier": 3.0735247135162354,
    "Safety/ShieldLagrangeMultiplier/Max": 3.0735247135162354,
    "Safety/ShieldLagrangeMultiplier/Min": 3.0735247135162354,
    "Safety/ShieldLagrangeMultiplier/Std": 0,
    "Safety/shield_adv_c": "NaN",
    "Safety/shield_violation": 3.814218044281006,
    "Time/Epoch": 180.3529815673828,
    "Time/FPS": 110.89364624023438,
    "Time/Rollout": 87.98384094238281,
    "Time/Total": 18767.169921875,
    "Time/Update": 92.36907958984376,
    "TotalEnvSteps": 2000000,
    "Train/Entropy": 0.3814140558242798,
    "Train/Epoch": 99,
    "Train/KL": 0.003538121236488223,
    "Train/LR": 0,
    "Train/PolicyRatio": 1.0000895261764526,
    "Train/PolicyRatio/Max": 1.0000895261764526,
    "Train/PolicyRatio/Min": 1.0000895261764526,
    "Train/PolicyRatio/Std": 0.006509391125291586,
    "Train/PolicyStd": 0.3556617200374603,
    "Train/StopIter": 40,
    "Value/Adv": 0.08881711959838867,
    "Value/cost": 1.236483812332153,
    "Value/reward": 0.02310154028236866,
    "_runtime": 18782.821087553,
    "_step": 100,
    "_timestamp": 1747269049.732237,
    "_wandb": {
        "runtime": 18782
    }
}