{
    "Loss/Loss_cost_critic": 0.9126849174499512,
    "Loss/Loss_cost_critic/Delta": -0.09811198711395264,
    "Loss/Loss_pi": 0.06817451864480972,
    "Loss/Loss_pi/Delta": 0.19184717535972595,
    "Loss/Loss_reward_critic": 0.006530707236379385,
    "Loss/Loss_reward_critic/Delta": -0.0005339691415429115,
    "Metrics/EpCost": 2.049999952316284,
    "Metrics/EpLen": 1000,
    "Metrics/EpRet": -0.008427977561950684,
    "Metrics/LagrangeMultiplier": 2.501589298248291,
    "Metrics/LagrangeMultiplier/Max": 2.501589298248291,
    "Metrics/LagrangeMultiplier/Min": 2.501589298248291,
    "Metrics/LagrangeMultiplier/Std": 0,
    "Safety/EpCostShield": 28.399999618530273,
    "Safety/ShieldLagrangeMultiplier": 3.058183193206787,
    "Safety/ShieldLagrangeMultiplier/Max": 3.058183193206787,
    "Safety/ShieldLagrangeMultiplier/Min": 3.058183193206787,
    "Safety/ShieldLagrangeMultiplier/Std": 0,
    "Safety/shield_adv_c": "NaN",
    "Safety/shield_violation": 1.777251124382019,
    "Time/Epoch": 184.26573181152344,
    "Time/FPS": 108.53890228271484,
    "Time/Rollout": 87.14656066894531,
    "Time/Total": 18732.84765625,
    "Time/Update": 97.11911010742188,
    "TotalEnvSteps": 2000000,
    "Train/Entropy": 0.7620351910591125,
    "Train/Epoch": 99,
    "Train/KL": 0.0036227006930857897,
    "Train/LR": 0,
    "Train/PolicyRatio": 1.000194787979126,
    "Train/PolicyRatio/Max": 1.0001949071884155,
    "Train/PolicyRatio/Min": 1.0001949071884155,
    "Train/PolicyRatio/Std": 0.006672061514109373,
    "Train/PolicyStd": 0.5188298225402832,
    "Train/StopIter": 40,
    "Value/Adv": 0.3641318678855896,
    "Value/cost": 0.4475125968456268,
    "Value/reward": 0.05090274661779404,
    "_runtime": 18733.768225351,
    "_step": 100,
    "_timestamp": 1746612302.1631017,
    "_wandb": {
        "runtime": 18733
    }
}