{
    "Loss/Loss_cost_critic": 0.32433146238327026,
    "Loss/Loss_cost_critic/Delta": -0.32300513982772827,
    "Loss/Loss_pi": -0.003351374063640833,
    "Loss/Loss_pi/Delta": 0.008204495999962091,
    "Loss/Loss_reward_critic": 0.0045006293803453445,
    "Loss/Loss_reward_critic/Delta": 0.0005156369879841805,
    "Metrics/EpCost": 6.400000095367432,
    "Metrics/EpLen": 1000,
    "Metrics/EpRet": 0.13475926220417023,
    "Metrics/LagrangeMultiplier": 2.885192394256592,
    "Metrics/LagrangeMultiplier/Max": 2.885192394256592,
    "Metrics/LagrangeMultiplier/Min": 2.885192394256592,
    "Metrics/LagrangeMultiplier/Std": 0,
    "Time/Epoch": 137.6651153564453,
    "Time/FPS": 145.28009033203125,
    "Time/Rollout": 75.98116302490234,
    "Time/Total": 13634.4248046875,
    "Time/Update": 61.68387222290039,
    "TotalEnvSteps": 2000000,
    "Train/Entropy": 0.33492112159729004,
    "Train/Epoch": 99,
    "Train/KL": 0.0031964851077646017,
    "Train/LR": 0,
    "Train/PolicyRatio": 0.9999361634254456,
    "Train/PolicyRatio/Max": 0.9999361634254456,
    "Train/PolicyRatio/Min": 0.9999361634254456,
    "Train/PolicyRatio/Std": 0.005471952725201845,
    "Train/PolicyStd": 0.3388461172580719,
    "Train/StopIter": 40,
    "Value/Adv": -0.07883724570274353,
    "Value/cost": 0.8853190541267395,
    "Value/reward": 0.03276629000902176,
    "_runtime": 13636.190595721,
    "_step": 100,
    "_timestamp": 1746912216.7123492,
    "_wandb": {
        "runtime": 13636
    }
}