{
    "Loss/Loss_cost_critic": 6.482364654541016,
    "Loss/Loss_cost_critic/Delta": -0.7766737937927246,
    "Loss/Loss_pi": -0.07926540076732635,
    "Loss/Loss_pi/Delta": -0.47033925354480743,
    "Loss/Loss_reward_critic": 0.06778983026742935,
    "Loss/Loss_reward_critic/Delta": 0.011361699551343918,
    "Metrics/EpCost": 35.66999816894531,
    "Metrics/EpLen": 1000,
    "Metrics/EpRet": 14.40466594696045,
    "Metrics/LagrangeMultiplier": 3.0103156566619873,
    "Metrics/LagrangeMultiplier/Max": 3.0103156566619873,
    "Metrics/LagrangeMultiplier/Min": 3.0103156566619873,
    "Metrics/LagrangeMultiplier/Std": 0,
    "Safety/EpCostShield": 54.25,
    "Safety/ShieldLagrangeMultiplier": 2.989049196243286,
    "Safety/ShieldLagrangeMultiplier/Max": 2.989049196243286,
    "Safety/ShieldLagrangeMultiplier/Min": 2.989049196243286,
    "Safety/ShieldLagrangeMultiplier/Std": 0,
    "Safety/shield_adv_c": "NaN",
    "Safety/shield_violation": 5.375268936157227,
    "Time/Epoch": 246.63478088378903,
    "Time/FPS": 81.09156036376953,
    "Time/Rollout": 101.76152801513672,
    "Time/Total": 21891.66796875,
    "Time/Update": 144.87318420410156,
    "TotalEnvSteps": 2000000,
    "Train/Entropy": -0.11509960889816284,
    "Train/Epoch": 99,
    "Train/KL": 0.004578381776809692,
    "Train/LR": 0,
    "Train/PolicyRatio": 0.9992393255233764,
    "Train/PolicyRatio/Max": 0.9992393851280212,
    "Train/PolicyRatio/Min": 0.9992393851280212,
    "Train/PolicyRatio/Std": 0.007200800813734531,
    "Train/PolicyStd": 0.2156652808189392,
    "Train/StopIter": 40,
    "Value/Adv": -0.15877020359039307,
    "Value/cost": 2.6766891479492188,
    "Value/reward": 1.3370158672332764,
    "_runtime": 21894.067024708,
    "_step": 100,
    "_timestamp": 1746640526.7274303,
    "_wandb": {
        "runtime": 21894
    }
}