{
    "Loss/Loss_cost_critic": 0.37081027030944824,
    "Loss/Loss_cost_critic/Delta": 0.24887249618768692,
    "Loss/Loss_pi": -0.008517573587596416,
    "Loss/Loss_pi/Delta": -0.006347698159515858,
    "Loss/Loss_reward_critic": 0.02007643505930901,
    "Loss/Loss_reward_critic/Delta": -0.002959733828902245,
    "Metrics/EpCost": 3.930000066757202,
    "Metrics/EpLen": 1000,
    "Metrics/EpRet": -0.7477490305900574,
    "Metrics/LagrangeMultiplier": 133.89369201660156,
    "Metrics/LagrangeMultiplier/Max": 133.89369201660156,
    "Metrics/LagrangeMultiplier/Min": 133.89369201660156,
    "Metrics/LagrangeMultiplier/Std": 0,
    "Time/Epoch": 124.3403778076172,
    "Time/FPS": 160.8488006591797,
    "Time/Rollout": 66.41505432128906,
    "Time/Total": 12046.6787109375,
    "Time/Update": 57.925270080566406,
    "TotalEnvSteps": 2000000,
    "Train/Entropy": 0.782538890838623,
    "Train/Epoch": 99,
    "Train/KL": 0.003746956586837769,
    "Train/LR": 0,
    "Train/PolicyRatio": 0.999783992767334,
    "Train/PolicyRatio/Max": 0.999783992767334,
    "Train/PolicyRatio/Min": 0.999783992767334,
    "Train/PolicyRatio/Std": 0.0069976444356143475,
    "Train/PolicyStd": 0.5322177410125732,
    "Train/StopIter": 40,
    "Value/Adv": -0.09634974598884584,
    "Value/cost": 0.3249585032463074,
    "Value/reward": -0.03363862261176109,
    "_runtime": 12047.800016353,
    "_step": 100,
    "_timestamp": 1745032512.6968858,
    "_wandb": {
        "runtime": 12047
    }
}