{
    "Loss/Loss_cost_critic": 1.4314817190170288,
    "Loss/Loss_cost_critic/Delta": 0.027679920196533203,
    "Loss/Loss_pi": -0.0058149294927716255,
    "Loss/Loss_pi/Delta": 0.00025831349194049835,
    "Loss/Loss_reward_critic": 0.035288307815790176,
    "Loss/Loss_reward_critic/Delta": 0.003771662712097168,
    "Metrics/EpCost": 40.7400016784668,
    "Metrics/EpLen": 1000,
    "Metrics/EpRet": 23.839614868164062,
    "Metrics/LagrangeMultiplier": 0.3351041376590729,
    "Metrics/LagrangeMultiplier/Max": 0.3351041376590729,
    "Metrics/LagrangeMultiplier/Min": 0.3351041376590729,
    "Metrics/LagrangeMultiplier/Std": 0,
    "Time/Epoch": 214.89569091796875,
    "Time/FPS": 93.06841278076172,
    "Time/Rollout": 82.50447845458984,
    "Time/Total": 21258.0390625,
    "Time/Update": 132.39111328125,
    "TotalEnvSteps": 2000000,
    "Train/Entropy": 0.20534679293632507,
    "Train/Epoch": 99,
    "Train/KL": 0.003843041136860847,
    "Train/LR": 0,
    "Train/PolicyRatio": 0.9996739625930786,
    "Train/PolicyRatio/Max": 0.9996740221977234,
    "Train/PolicyRatio/Min": 0.9996740221977234,
    "Train/PolicyRatio/Std": 0.006450899876654148,
    "Train/PolicyStd": 0.2993106544017792,
    "Train/StopIter": 40,
    "Value/Adv": -0.12083001434803008,
    "Value/cost": 5.179387092590332,
    "Value/reward": 2.295875072479248,
    "_runtime": 21259.840666818,
    "_step": 100,
    "_timestamp": 1745040007.9451473,
    "_wandb": {
        "runtime": 21259
    }
}