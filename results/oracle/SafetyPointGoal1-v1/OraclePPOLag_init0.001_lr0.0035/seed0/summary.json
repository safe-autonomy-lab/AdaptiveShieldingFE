{
    "Loss/Loss_cost_critic": 1.6159722805023191,
    "Loss/Loss_cost_critic/Delta": 0.05723154544830322,
    "Loss/Loss_pi": -0.004813731648027897,
    "Loss/Loss_pi/Delta": 0.003078274428844452,
    "Loss/Loss_reward_critic": 0.03112458437681198,
    "Loss/Loss_reward_critic/Delta": -0.0037692151963710785,
    "Metrics/EpCost": 40.58000183105469,
    "Metrics/EpLen": 1000,
    "Metrics/EpRet": 24.048534393310547,
    "Metrics/LagrangeMultiplier": 0.3278915584087372,
    "Metrics/LagrangeMultiplier/Max": 0.3278915584087372,
    "Metrics/LagrangeMultiplier/Min": 0.3278915584087372,
    "Metrics/LagrangeMultiplier/Std": 0,
    "Time/Epoch": 210.57508850097656,
    "Time/FPS": 94.97799682617188,
    "Time/Rollout": 83.69293212890625,
    "Time/Total": 21447.693359375,
    "Time/Update": 126.88204956054688,
    "TotalEnvSteps": 2000000,
    "Train/Entropy": 0.15861445665359497,
    "Train/Epoch": 99,
    "Train/KL": 0.003173726610839367,
    "Train/LR": 0,
    "Train/PolicyRatio": 0.9999154806137084,
    "Train/PolicyRatio/Max": 0.9999154806137084,
    "Train/PolicyRatio/Min": 0.9999154806137084,
    "Train/PolicyRatio/Std": 0.006176391616463661,
    "Train/PolicyStd": 0.2837977409362793,
    "Train/StopIter": 40,
    "Value/Adv": 0.17393997311592102,
    "Value/cost": 4.559147834777832,
    "Value/reward": 2.425428867340088,
    "_runtime": 21448.936871109,
    "_step": 100,
    "_timestamp": 1745040175.9396515,
    "_wandb": {
        "runtime": 21448
    }
}