{
    "Loss/Loss_cost_critic": 1.6545485258102417,
    "Loss/Loss_cost_critic/Delta": -0.2849537134170532,
    "Loss/Loss_pi": -0.015913894400000572,
    "Loss/Loss_pi/Delta": 0.0018517374992370603,
    "Loss/Loss_reward_critic": 0.04155372083187103,
    "Loss/Loss_reward_critic/Delta": 0.000287473201751709,
    "Metrics/EpCost": 44.040000915527344,
    "Metrics/EpLen": 1000,
    "Metrics/EpRet": 15.24838638305664,
    "Metrics/LagrangeMultiplier": 3.0634167194366455,
    "Metrics/LagrangeMultiplier/Max": 3.0634167194366455,
    "Metrics/LagrangeMultiplier/Min": 3.0634167194366455,
    "Metrics/LagrangeMultiplier/Std": 0,
    "Misc/AcceptanceStep": 1,
    "Misc/Alpha": 0.8015382289886475,
    "Misc/FinalStepNorm": 0.2652267515659332,
    "Misc/H_inv_g": 0.33089718222618103,
    "Misc/gradient_norm": 0.3481992781162262,
    "Misc/xHx": 0.03113016113638878,
    "Time/Epoch": 74.52169799804688,
    "Time/FPS": 268.3782043457031,
    "Time/Rollout": 66.15872955322266,
    "Time/Total": 8085.6435546875,
    "Time/Update": 8.362953186035156,
    "TotalEnvSteps": 2000000,
    "Train/Entropy": 1.097507119178772,
    "Train/Epoch": 99,
    "Train/KL": 0.00037964468356221914,
    "Train/LR": 0,
    "Train/PolicyRatio": 1.0002931356430054,
    "Train/PolicyRatio/Max": 1.0002931356430054,
    "Train/PolicyRatio/Min": 1.0002931356430054,
    "Train/PolicyRatio/Std": 0.00020719393796753136,
    "Train/PolicyStd": 0.7293667197227478,
    "Train/StopIter": 10,
    "Value/Adv": 2.2888182460434332e-09,
    "Value/cost": 4.035311222076416,
    "Value/reward": 1.5975208282470703,
    "_runtime": 8088.032966492,
    "_step": 100,
    "_timestamp": 1743314017.7517824,
    "_wandb": {
        "runtime": 8088
    }
}