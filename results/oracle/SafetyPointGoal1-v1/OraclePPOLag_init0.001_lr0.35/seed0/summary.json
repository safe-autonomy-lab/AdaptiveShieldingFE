{
    "Loss/Loss_cost_critic": 0.2279244214296341,
    "Loss/Loss_cost_critic/Delta": -1.0612611025571823,
    "Loss/Loss_pi": -0.0021315740887075663,
    "Loss/Loss_pi/Delta": 0.00554530811496079,
    "Loss/Loss_reward_critic": 0.016322052106261253,
    "Loss/Loss_reward_critic/Delta": -0.002414776012301445,
    "Metrics/EpCost": 4.920000076293945,
    "Metrics/EpLen": 1000,
    "Metrics/EpRet": 0.3046838343143463,
    "Metrics/LagrangeMultiplier": 18.92662811279297,
    "Metrics/LagrangeMultiplier/Max": 18.92662811279297,
    "Metrics/LagrangeMultiplier/Min": 18.92662811279297,
    "Metrics/LagrangeMultiplier/Std": 0,
    "Time/Epoch": 151.0808868408203,
    "Time/FPS": 132.37940979003906,
    "Time/Rollout": 72.47940063476562,
    "Time/Total": 15002.9873046875,
    "Time/Update": 78.6014404296875,
    "TotalEnvSteps": 2000000,
    "Train/Entropy": 0.8224843144416809,
    "Train/Epoch": 99,
    "Train/KL": 0.003866887884214521,
    "Train/LR": 0,
    "Train/PolicyRatio": 0.9994922876358032,
    "Train/PolicyRatio/Max": 0.9994922876358032,
    "Train/PolicyRatio/Min": 0.9994922876358032,
    "Train/PolicyRatio/Std": 0.006310282275080681,
    "Train/PolicyStd": 0.5510918498039246,
    "Train/StopIter": 40,
    "Value/Adv": -0.14262092113494873,
    "Value/cost": 0.2216252237558365,
    "Value/reward": -0.00023695602430962023,
    "_runtime": 15003.882427227,
    "_step": 100,
    "_timestamp": 1745034070.851337,
    "_wandb": {
        "runtime": 15003
    }
}