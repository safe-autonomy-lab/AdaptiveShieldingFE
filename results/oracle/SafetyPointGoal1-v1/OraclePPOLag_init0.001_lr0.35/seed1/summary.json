{
    "Loss/Loss_cost_critic": 0.2689431607723236,
    "Loss/Loss_cost_critic/Delta": -0.3629307448863983,
    "Loss/Loss_pi": -0.003615070367231965,
    "Loss/Loss_pi/Delta": 0.003484491491690278,
    "Loss/Loss_reward_critic": 0.018566126003861427,
    "Loss/Loss_reward_critic/Delta": -0.005409799516201019,
    "Metrics/EpCost": 6.409999847412109,
    "Metrics/EpLen": 1000,
    "Metrics/EpRet": 2.10805606842041,
    "Metrics/LagrangeMultiplier": 21.652109146118164,
    "Metrics/LagrangeMultiplier/Max": 21.652109146118164,
    "Metrics/LagrangeMultiplier/Min": 21.652109146118164,
    "Metrics/LagrangeMultiplier/Std": 0,
    "Time/Epoch": 214.03585815429688,
    "Time/FPS": 93.44229125976562,
    "Time/Rollout": 84.45260620117188,
    "Time/Total": 21279.41015625,
    "Time/Update": 129.58311462402344,
    "TotalEnvSteps": 2000000,
    "Train/Entropy": 0.8000093102455139,
    "Train/Epoch": 99,
    "Train/KL": 0.002963848877698183,
    "Train/LR": 0,
    "Train/PolicyRatio": 0.9996689558029176,
    "Train/PolicyRatio/Max": 0.9996689558029176,
    "Train/PolicyRatio/Min": 0.9996689558029176,
    "Train/PolicyRatio/Std": 0.005979990120977163,
    "Train/PolicyStd": 0.5385230779647827,
    "Train/StopIter": 40,
    "Value/Adv": 0.15680058300495148,
    "Value/cost": 0.42961424589157104,
    "Value/reward": 0.14300112426280975,
    "_runtime": 21280.75104034,
    "_step": 100,
    "_timestamp": 1745040735.3394687,
    "_wandb": {
        "runtime": 21280
    }
}