{
    "Loss/Loss_cost_critic": 0.2987127900123596,
    "Loss/Loss_cost_critic/Delta": -0.02087363600730896,
    "Loss/Loss_pi": -0.0034749116748571396,
    "Loss/Loss_pi/Delta": 0.0023063085973262787,
    "Loss/Loss_reward_critic": 0.021628566086292267,
    "Loss/Loss_reward_critic/Delta": -0.0012535583227872849,
    "Metrics/EpCost": 5.699999809265137,
    "Metrics/EpLen": 1000,
    "Metrics/EpRet": 2.2895936965942383,
    "Metrics/LagrangeMultiplier": 19.140594482421875,
    "Metrics/LagrangeMultiplier/Max": 19.140594482421875,
    "Metrics/LagrangeMultiplier/Min": 19.140594482421875,
    "Metrics/LagrangeMultiplier/Std": 0,
    "Time/Epoch": 182.62716674804688,
    "Time/FPS": 109.51273345947266,
    "Time/Rollout": 78.27953338623047,
    "Time/Total": 17880.158203125,
    "Time/Update": 104.3475112915039,
    "TotalEnvSteps": 2000000,
    "Train/Entropy": 0.7376822233200073,
    "Train/Epoch": 99,
    "Train/KL": 0.0032152424100786448,
    "Train/LR": 0,
    "Train/PolicyRatio": 0.9995214939117432,
    "Train/PolicyRatio/Max": 0.999521553516388,
    "Train/PolicyRatio/Min": 0.999521553516388,
    "Train/PolicyRatio/Std": 0.005846919491887093,
    "Train/PolicyStd": 0.5060034394264221,
    "Train/StopIter": 40,
    "Value/Adv": 0.3189927637577057,
    "Value/cost": 0.987273633480072,
    "Value/reward": 0.2509962022304535,
    "_runtime": 17882.113041462,
    "_step": 100,
    "_timestamp": 1745037684.3967285,
    "_wandb": {
        "runtime": 17882
    }
}