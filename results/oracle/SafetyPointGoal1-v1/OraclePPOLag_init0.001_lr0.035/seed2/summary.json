{
    "Loss/Loss_cost_critic": 0.9521369338035583,
    "Loss/Loss_cost_critic/Delta": -0.2535476088523865,
    "Loss/Loss_pi": -0.004841698333621025,
    "Loss/Loss_pi/Delta": 0.0052523622289299965,
    "Loss/Loss_reward_critic": 0.03836854174733162,
    "Loss/Loss_reward_critic/Delta": 7.308274507522583e-05,
    "Metrics/EpCost": 24.540000915527344,
    "Metrics/EpLen": 1000,
    "Metrics/EpRet": 22.107099533081055,
    "Metrics/LagrangeMultiplier": 3.2322041988372803,
    "Metrics/LagrangeMultiplier/Max": 3.2322041988372803,
    "Metrics/LagrangeMultiplier/Min": 3.2322041988372803,
    "Metrics/LagrangeMultiplier/Std": 0,
    "Time/Epoch": 125.48372650146484,
    "Time/FPS": 159.3832244873047,
    "Time/Rollout": 66.87307739257812,
    "Time/Total": 15148.771484375,
    "Time/Update": 58.610591888427734,
    "TotalEnvSteps": 2000000,
    "Train/Entropy": 0.593521237373352,
    "Train/Epoch": 99,
    "Train/KL": 0.003245360916480422,
    "Train/LR": 0,
    "Train/PolicyRatio": 1.0001561641693115,
    "Train/PolicyRatio/Max": 1.0001561641693115,
    "Train/PolicyRatio/Min": 1.0001561641693115,
    "Train/PolicyRatio/Std": 0.006081331055611372,
    "Train/PolicyStd": 0.4420267343521118,
    "Train/StopIter": 40,
    "Value/Adv": -0.14215832948684692,
    "Value/cost": 3.119946241378784,
    "Value/reward": 2.2593281269073486,
    "_runtime": 15150.561532275,
    "_step": 100,
    "_timestamp": 1743321081.511093,
    "_wandb": {
        "runtime": 15150
    }
}