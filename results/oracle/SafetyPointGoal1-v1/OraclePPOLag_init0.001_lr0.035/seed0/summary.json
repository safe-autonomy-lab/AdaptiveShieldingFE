{
    "Loss/Loss_cost_critic": 1.212818264961243,
    "Loss/Loss_cost_critic/Delta": -0.5183424949645996,
    "Loss/Loss_pi": -0.007308619096875191,
    "Loss/Loss_pi/Delta": 0.007390599697828293,
    "Loss/Loss_reward_critic": 0.032246604561805725,
    "Loss/Loss_reward_critic/Delta": -0.001254301518201828,
    "Metrics/EpCost": 32.380001068115234,
    "Metrics/EpLen": 1000,
    "Metrics/EpRet": 19.630224227905273,
    "Metrics/LagrangeMultiplier": 3.2351884841918945,
    "Metrics/LagrangeMultiplier/Max": 3.2351884841918945,
    "Metrics/LagrangeMultiplier/Min": 3.2351884841918945,
    "Metrics/LagrangeMultiplier/Std": 0,
    "Time/Epoch": 124.55453491210938,
    "Time/FPS": 160.57223510742188,
    "Time/Rollout": 65.97860717773438,
    "Time/Total": 14474.9453125,
    "Time/Update": 58.57586288452149,
    "TotalEnvSteps": 2000000,
    "Train/Entropy": 0.6998640298843384,
    "Train/Epoch": 99,
    "Train/KL": 0.003362753894180059,
    "Train/LR": 0,
    "Train/PolicyRatio": 0.9996646046638488,
    "Train/PolicyRatio/Max": 0.9996646046638488,
    "Train/PolicyRatio/Min": 0.9996646046638488,
    "Train/PolicyRatio/Std": 0.006332939025014639,
    "Train/PolicyStd": 0.4899641871452331,
    "Train/StopIter": 40,
    "Value/Adv": -0.20445743203163147,
    "Value/cost": 4.409592151641846,
    "Value/reward": 1.980241060256958,
    "_runtime": 14476.246431054,
    "_step": 100,
    "_timestamp": 1743320407.5118833,
    "_wandb": {
        "runtime": 14476
    }
}