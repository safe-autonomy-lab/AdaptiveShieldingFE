{
    "Loss/Loss_cost_critic": 2.541820287704468,
    "Loss/Loss_cost_critic/Delta": 0.655759334564209,
    "Loss/Loss_pi": -0.015441986732184889,
    "Loss/Loss_pi/Delta": -0.0015539061278104782,
    "Loss/Loss_reward_critic": 0.1444193720817566,
    "Loss/Loss_reward_critic/Delta": 0.04464908689260483,
    "Metrics/EpCost": 54.5,
    "Metrics/EpLen": 1000,
    "Metrics/EpRet": 20.552793502807617,
    "Metrics/LagrangeMultiplier": 0.34807318449020386,
    "Metrics/LagrangeMultiplier/Max": 0.34807318449020386,
    "Metrics/LagrangeMultiplier/Min": 0.34807318449020386,
    "Metrics/LagrangeMultiplier/Std": 0,
    "Misc/AcceptanceStep": 1,
    "Misc/Alpha": 0.8258024454116821,
    "Misc/FinalStepNorm": 0.17838798463344574,
    "Misc/H_inv_g": 0.21601775288581848,
    "Misc/gradient_norm": 0.48350754380226135,
    "Misc/xHx": 0.02932766824960709,
    "Time/Epoch": 108.77384185791016,
    "Time/FPS": 183.8677520751953,
    "Time/Rollout": 94.06111145019533,
    "Time/Total": 10729.8642578125,
    "Time/Update": 14.712696075439451,
    "TotalEnvSteps": 2000000,
    "Train/Entropy": 0.5807571411132812,
    "Train/Epoch": 99,
    "Train/KL": 0.0004669322224799544,
    "Train/LR": 0,
    "Train/PolicyRatio": 1.001903057098389,
    "Train/PolicyRatio/Max": 1.001903057098389,
    "Train/PolicyRatio/Min": 1.001903057098389,
    "Train/PolicyRatio/Std": 0.001345664612017572,
    "Train/PolicyStd": 0.433431476354599,
    "Train/StopIter": 10,
    "Value/Adv": 1.2207030941624453e-08,
    "Value/cost": 5.7555413246154785,
    "Value/reward": 2.552863836288452,
    "_runtime": 10731.593713971,
    "_step": 100,
    "_timestamp": 1745027828.9061918,
    "_wandb": {
        "runtime": 10731
    }
}