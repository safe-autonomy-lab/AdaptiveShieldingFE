{
    "Loss/Loss_cost_critic": 0.26088204979896545,
    "Loss/Loss_cost_critic/Delta": -0.4742172062397003,
    "Loss/Loss_pi": -0.0024461490102112293,
    "Loss/Loss_pi/Delta": 0.027408660855144262,
    "Loss/Loss_reward_critic": 0.007198916748166084,
    "Loss/Loss_reward_critic/Delta": -0.004819354973733425,
    "Metrics/EpCost": 21.479999542236328,
    "Metrics/EpLen": 1000,
    "Metrics/EpRet": -0.877765953540802,
    "Metrics/LagrangeMultiplier": 190.2906036376953,
    "Metrics/LagrangeMultiplier/Max": 190.2906036376953,
    "Metrics/LagrangeMultiplier/Min": 190.2906036376953,
    "Metrics/LagrangeMultiplier/Std": 0,
    "Time/Epoch": 231.6942901611328,
    "Time/FPS": 86.32064056396484,
    "Time/Rollout": 99.97452545166016,
    "Time/Total": 20190.060546875,
    "Time/Update": 131.7196502685547,
    "TotalEnvSteps": 2000000,
    "Train/Entropy": 0.3154357671737671,
    "Train/Epoch": 99,
    "Train/KL": 0.003273824229836464,
    "Train/LR": 0,
    "Train/PolicyRatio": 0.999987244606018,
    "Train/PolicyRatio/Max": 0.999987244606018,
    "Train/PolicyRatio/Min": 0.999987244606018,
    "Train/PolicyRatio/Std": 0.005352734122425318,
    "Train/PolicyStd": 0.33529147505760193,
    "Train/StopIter": 40,
    "Value/Adv": -0.11058473587036131,
    "Value/cost": 0.8019090890884399,
    "Value/reward": -0.09207149595022202,
    "_runtime": 20191.419482206,
    "_step": 100,
    "_timestamp": 1745060242.06935,
    "_wandb": {
        "runtime": 20191
    }
}