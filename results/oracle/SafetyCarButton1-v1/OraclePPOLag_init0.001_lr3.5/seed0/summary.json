{
    "Loss/Loss_cost_critic": 0.002066119806841016,
    "Loss/Loss_cost_critic/Delta": -0.005412829341366887,
    "Loss/Loss_pi": -0.0002463540295138955,
    "Loss/Loss_pi/Delta": 0.00048145343316718936,
    "Loss/Loss_reward_critic": 0.014837555587291718,
    "Loss/Loss_reward_critic/Delta": -0.005906354635953903,
    "Metrics/EpCost": 0.7099999785423279,
    "Metrics/EpLen": 1000,
    "Metrics/EpRet": -2.561728000640869,
    "Metrics/LagrangeMultiplier": 190.73117065429688,
    "Metrics/LagrangeMultiplier/Max": 190.73117065429688,
    "Metrics/LagrangeMultiplier/Min": 190.73117065429688,
    "Metrics/LagrangeMultiplier/Std": 0,
    "Time/Epoch": 143.0058135986328,
    "Time/FPS": 139.85446166992188,
    "Time/Rollout": 83.30317687988281,
    "Time/Total": 12662.0927734375,
    "Time/Update": 59.70257186889648,
    "TotalEnvSteps": 2000000,
    "Train/Entropy": 0.3480142056941986,
    "Train/Epoch": 99,
    "Train/KL": 0.0034166525583714247,
    "Train/LR": 0,
    "Train/PolicyRatio": 1.0003584623336792,
    "Train/PolicyRatio/Max": 1.0003584623336792,
    "Train/PolicyRatio/Min": 1.0003584623336792,
    "Train/PolicyRatio/Std": 0.006069515831768513,
    "Train/PolicyStd": 0.3432387411594391,
    "Train/StopIter": 40,
    "Value/Adv": 0.31351643800735474,
    "Value/cost": 0.07095997035503387,
    "Value/reward": -0.22741223871707916,
    "_runtime": 12663.497004502,
    "_step": 100,
    "_timestamp": 1745052111.9627447,
    "_wandb": {
        "runtime": 12663
    }
}