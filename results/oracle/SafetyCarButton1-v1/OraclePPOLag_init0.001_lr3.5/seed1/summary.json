{
    "Loss/Loss_cost_critic": 0.2280697226524353,
    "Loss/Loss_cost_critic/Delta": 0.19899326004087925,
    "Loss/Loss_pi": -0.006340986117720604,
    "Loss/Loss_pi/Delta": -0.005285552470013499,
    "Loss/Loss_reward_critic": 0.010701695457100868,
    "Loss/Loss_reward_critic/Delta": 0.00512243527919054,
    "Metrics/EpCost": 2.2100000381469727,
    "Metrics/EpLen": 1000,
    "Metrics/EpRet": -0.2922128438949585,
    "Metrics/LagrangeMultiplier": 139.59805297851562,
    "Metrics/LagrangeMultiplier/Max": 139.59805297851562,
    "Metrics/LagrangeMultiplier/Min": 139.59805297851562,
    "Metrics/LagrangeMultiplier/Std": 0,
    "Time/Epoch": 167.71849060058594,
    "Time/FPS": 119.2474365234375,
    "Time/Rollout": 87.73450469970703,
    "Time/Total": 14719.35546875,
    "Time/Update": 79.98393249511719,
    "TotalEnvSteps": 2000000,
    "Train/Entropy": 0.46477386355400085,
    "Train/Epoch": 99,
    "Train/KL": 0.005155709106475115,
    "Train/LR": 0,
    "Train/PolicyRatio": 1.0006030797958374,
    "Train/PolicyRatio/Max": 1.0006030797958374,
    "Train/PolicyRatio/Min": 1.0006030797958374,
    "Train/PolicyRatio/Std": 0.00833958201110363,
    "Train/PolicyStd": 0.38515836000442505,
    "Train/StopIter": 40,
    "Value/Adv": 0.3167015314102173,
    "Value/cost": 0.20682846009731293,
    "Value/reward": -0.06947875022888184,
    "_runtime": 14720.802329262,
    "_step": 100,
    "_timestamp": 1745054201.813628,
    "_wandb": {
        "runtime": 14720
    }
}