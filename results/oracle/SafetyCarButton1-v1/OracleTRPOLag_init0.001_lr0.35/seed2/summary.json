{
    "Loss/Loss_cost_critic": 0.856623649597168,
    "Loss/Loss_cost_critic/Delta": 0.5634989142417908,
    "Loss/Loss_pi": -0.026488954201340675,
    "Loss/Loss_pi/Delta": -0.01314034964889288,
    "Loss/Loss_reward_critic": 0.017987975850701332,
    "Loss/Loss_reward_critic/Delta": 8.368119597434998e-05,
    "Metrics/EpCost": 12.979999542236328,
    "Metrics/EpLen": 1000,
    "Metrics/EpRet": 1.2136259078979492,
    "Metrics/LagrangeMultiplier": 21.65318298339844,
    "Metrics/LagrangeMultiplier/Max": 21.65318298339844,
    "Metrics/LagrangeMultiplier/Min": 21.65318298339844,
    "Metrics/LagrangeMultiplier/Std": 0,
    "Misc/AcceptanceStep": 1,
    "Misc/Alpha": 0.5570741295814514,
    "Misc/FinalStepNorm": 0.251315176486969,
    "Misc/H_inv_g": 0.4511341452598572,
    "Misc/gradient_norm": 0.27587151527404785,
    "Misc/xHx": 0.06444718688726425,
    "Time/Epoch": 119.23158264160156,
    "Time/FPS": 167.74078369140625,
    "Time/Rollout": 99.2855224609375,
    "Time/Total": 11931.2509765625,
    "Time/Update": 19.946033477783203,
    "TotalEnvSteps": 2000000,
    "Train/Entropy": 1.6279436349868774,
    "Train/Epoch": 99,
    "Train/KL": 0.0003608504193834961,
    "Train/LR": 0,
    "Train/PolicyRatio": 1.000452995300293,
    "Train/PolicyRatio/Max": 1.000452995300293,
    "Train/PolicyRatio/Min": 1.000452995300293,
    "Train/PolicyRatio/Std": 0.0003203160595148802,
    "Train/PolicyStd": 1.2422562837600708,
    "Train/StopIter": 10,
    "Value/Adv": -1.5258788677030564e-09,
    "Value/cost": 0.6470680832862854,
    "Value/reward": 0.20076020061969757,
    "_runtime": 11932.636937708,
    "_step": 100,
    "_timestamp": 1745030742.2591867,
    "_wandb": {
        "runtime": 11932
    }
}