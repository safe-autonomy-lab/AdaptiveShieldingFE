{
    "Loss/Loss_cost_critic": 0.4619111120700836,
    "Loss/Loss_cost_critic/Delta": 0.1194581389427185,
    "Loss/Loss_pi": -0.017838766798377037,
    "Loss/Loss_pi/Delta": -0.007241157814860344,
    "Loss/Loss_reward_critic": 0.02400605008006096,
    "Loss/Loss_reward_critic/Delta": 0.006706524640321732,
    "Metrics/EpCost": 8.569999694824219,
    "Metrics/EpLen": 1000,
    "Metrics/EpRet": 1.3366551399230957,
    "Metrics/LagrangeMultiplier": 23.79673957824707,
    "Metrics/LagrangeMultiplier/Max": 23.79673957824707,
    "Metrics/LagrangeMultiplier/Min": 23.79673957824707,
    "Metrics/LagrangeMultiplier/Std": 0,
    "Time/Epoch": 195.79345703125,
    "Time/FPS": 102.1484603881836,
    "Time/Rollout": 92.8283462524414,
    "Time/Total": 16939.2265625,
    "Time/Update": 102.96497344970705,
    "TotalEnvSteps": 2000000,
    "Train/Entropy": 0.5982263088226318,
    "Train/Epoch": 99,
    "Train/KL": 0.003687437390908599,
    "Train/LR": 0,
    "Train/PolicyRatio": 1.00139319896698,
    "Train/PolicyRatio/Max": 1.00139319896698,
    "Train/PolicyRatio/Min": 1.00139319896698,
    "Train/PolicyRatio/Std": 0.006952542345970869,
    "Train/PolicyStd": 0.4401302635669708,
    "Train/StopIter": 40,
    "Value/Adv": -0.07869887351989746,
    "Value/cost": 1.3664251565933228,
    "Value/reward": 0.18707892298698425,
    "_runtime": 16941.099310822,
    "_step": 100,
    "_timestamp": 1745053832.5000536,
    "_wandb": {
        "runtime": 16941
    }
}