{
    "Loss/Loss_cost_critic": 0.11013857275247574,
    "Loss/Loss_cost_critic/Delta": -0.005760781466960907,
    "Loss/Loss_pi": -0.0028809180948883295,
    "Loss/Loss_pi/Delta": 0.0023886559065431356,
    "Loss/Loss_reward_critic": 0.002952639712020755,
    "Loss/Loss_reward_critic/Delta": -0.0004368990194052458,
    "Metrics/EpCost": 1.8799999952316284,
    "Metrics/EpLen": 1000,
    "Metrics/EpRet": -0.09940361231565475,
    "Metrics/LagrangeMultiplier": 210.8887176513672,
    "Metrics/LagrangeMultiplier/Max": 210.8887176513672,
    "Metrics/LagrangeMultiplier/Min": 210.8887176513672,
    "Metrics/LagrangeMultiplier/Std": 0,
    "Time/Epoch": 201.23684692382812,
    "Time/FPS": 99.3853759765625,
    "Time/Rollout": 98.07257080078124,
    "Time/Total": 17500.1796875,
    "Time/Update": 103.16422271728516,
    "TotalEnvSteps": 2000000,
    "Train/Entropy": 0.08491973578929901,
    "Train/Epoch": 99,
    "Train/KL": 0.004477684386074543,
    "Train/LR": 0,
    "Train/PolicyRatio": 1.000495433807373,
    "Train/PolicyRatio/Max": 1.000495433807373,
    "Train/PolicyRatio/Min": 1.000495433807373,
    "Train/PolicyRatio/Std": 0.0072265430353581905,
    "Train/PolicyStd": 0.26606130599975586,
    "Train/StopIter": 40,
    "Value/Adv": -0.019956573843955994,
    "Value/cost": 0.04758876189589501,
    "Value/reward": -0.0064149536192417145,
    "_runtime": 17501.900844591,
    "_step": 100,
    "_timestamp": 1745049879.895764,
    "_wandb": {
        "runtime": 17501
    }
}