{
    "Loss/Loss_cost_critic": 0.1958656907081604,
    "Loss/Loss_cost_critic/Delta": -0.569021999835968,
    "Loss/Loss_pi": -0.003865825710818171,
    "Loss/Loss_pi/Delta": 0.008502766722813249,
    "Loss/Loss_reward_critic": 0.00714902812615037,
    "Loss/Loss_reward_critic/Delta": -0.00488863093778491,
    "Metrics/EpCost": 11.079999923706056,
    "Metrics/EpLen": 1000,
    "Metrics/EpRet": -0.23020599782466888,
    "Metrics/LagrangeMultiplier": 181.5409240722656,
    "Metrics/LagrangeMultiplier/Max": 181.5409240722656,
    "Metrics/LagrangeMultiplier/Min": 181.5409240722656,
    "Metrics/LagrangeMultiplier/Std": 0,
    "Time/Epoch": 193.6017303466797,
    "Time/FPS": 103.30486297607422,
    "Time/Rollout": 95.60049438476562,
    "Time/Total": 17293.2734375,
    "Time/Update": 98.00115203857422,
    "TotalEnvSteps": 2000000,
    "Train/Entropy": 0.4305641949176788,
    "Train/Epoch": 99,
    "Train/KL": 0.0035301963798701763,
    "Train/LR": 0,
    "Train/PolicyRatio": 1.0002493858337402,
    "Train/PolicyRatio/Max": 1.0002493858337402,
    "Train/PolicyRatio/Min": 1.0002493858337402,
    "Train/PolicyRatio/Std": 0.00621583079919219,
    "Train/PolicyStd": 0.3737107217311859,
    "Train/StopIter": 40,
    "Value/Adv": 0.15864554047584534,
    "Value/cost": 0.8017677664756775,
    "Value/reward": -0.026750139892101288,
    "_runtime": 17294.983375895,
    "_step": 100,
    "_timestamp": 1745049724.593486,
    "_wandb": {
        "runtime": 17294
    }
}