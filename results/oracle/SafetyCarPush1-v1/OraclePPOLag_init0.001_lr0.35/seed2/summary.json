{
    "Loss/Loss_cost_critic": 0.03609098121523857,
    "Loss/Loss_cost_critic/Delta": -0.005746606737375259,
    "Loss/Loss_pi": -0.0011846382403746247,
    "Loss/Loss_pi/Delta": 0.0010850484250113368,
    "Loss/Loss_reward_critic": 0.008174436166882515,
    "Loss/Loss_reward_critic/Delta": -0.0008363602682948112,
    "Metrics/EpCost": 1.1799999475479126,
    "Metrics/EpLen": 1000,
    "Metrics/EpRet": 0.04081267490983009,
    "Metrics/LagrangeMultiplier": 22.51912498474121,
    "Metrics/LagrangeMultiplier/Max": 22.51912498474121,
    "Metrics/LagrangeMultiplier/Min": 22.51912498474121,
    "Metrics/LagrangeMultiplier/Std": 0,
    "Time/Epoch": 195.35787963867188,
    "Time/FPS": 102.37621307373048,
    "Time/Rollout": 95.51202392578124,
    "Time/Total": 16284.693359375,
    "Time/Update": 99.84576416015624,
    "TotalEnvSteps": 2000000,
    "Train/Entropy": 0.18153251707553864,
    "Train/Epoch": 99,
    "Train/KL": 0.0035092101898044348,
    "Train/LR": 0,
    "Train/PolicyRatio": 1.0002641677856443,
    "Train/PolicyRatio/Max": 1.0002641677856443,
    "Train/PolicyRatio/Min": 1.0002641677856443,
    "Train/PolicyRatio/Std": 0.0060768392868340015,
    "Train/PolicyStd": 0.29031750559806824,
    "Train/StopIter": 40,
    "Value/Adv": -0.2491234838962555,
    "Value/cost": 0.22197841107845304,
    "Value/reward": 0.010442454367876053,
    "_runtime": 16285.945080627,
    "_step": 100,
    "_timestamp": 1745047634.594561,
    "_wandb": {
        "runtime": 16285
    }
}