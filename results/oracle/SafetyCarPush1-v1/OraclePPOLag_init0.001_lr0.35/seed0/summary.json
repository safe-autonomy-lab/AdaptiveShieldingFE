{
    "Loss/Loss_cost_critic": 0.3643780648708343,
    "Loss/Loss_cost_critic/Delta": -0.23745575547218323,
    "Loss/Loss_pi": -0.00603129155933857,
    "Loss/Loss_pi/Delta": 0.008511719293892384,
    "Loss/Loss_reward_critic": 0.006782424170523882,
    "Loss/Loss_reward_critic/Delta": -0.0006806422024965286,
    "Metrics/EpCost": 4.849999904632568,
    "Metrics/EpLen": 1000,
    "Metrics/EpRet": 0.12553589046001434,
    "Metrics/LagrangeMultiplier": 24.934232711791992,
    "Metrics/LagrangeMultiplier/Max": 24.934232711791992,
    "Metrics/LagrangeMultiplier/Min": 24.934232711791992,
    "Metrics/LagrangeMultiplier/Std": 0,
    "Time/Epoch": 117.38552856445312,
    "Time/FPS": 170.37875366210938,
    "Time/Rollout": 69.09577941894531,
    "Time/Total": 10390.0205078125,
    "Time/Update": 48.28971099853515,
    "TotalEnvSteps": 2000000,
    "Train/Entropy": 0.1791021227836609,
    "Train/Epoch": 99,
    "Train/KL": 0.004408579785376787,
    "Train/LR": 0,
    "Train/PolicyRatio": 1.0009536743164062,
    "Train/PolicyRatio/Max": 1.0009536743164062,
    "Train/PolicyRatio/Min": 1.0009536743164062,
    "Train/PolicyRatio/Std": 0.00689851725474,
    "Train/PolicyStd": 0.2945593297481537,
    "Train/StopIter": 40,
    "Value/Adv": 0.13523466885089874,
    "Value/cost": 0.3392270505428314,
    "Value/reward": 0.03928182274103165,
    "_runtime": 10391.005343206,
    "_step": 100,
    "_timestamp": 1745039414.9016638,
    "_wandb": {
        "runtime": 10391
    }
}