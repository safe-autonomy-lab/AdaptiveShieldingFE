{
    "Loss/Loss_cost_critic": 1.7912793159484863,
    "Loss/Loss_cost_critic/Delta": -0.5527544021606445,
    "Loss/Loss_pi": -0.01577119342982769,
    "Loss/Loss_pi/Delta": 0.009558450430631638,
    "Loss/Loss_reward_critic": 0.038574524223804474,
    "Loss/Loss_reward_critic/Delta": -0.0008591562509536743,
    "Metrics/EpCost": 61.56999969482422,
    "Metrics/EpLen": 1000,
    "Metrics/EpRet": 7.515799522399902,
    "Metrics/LagrangeMultiplier": 3.250288963317871,
    "Metrics/LagrangeMultiplier/Max": 3.250288963317871,
    "Metrics/LagrangeMultiplier/Min": 3.250288963317871,
    "Metrics/LagrangeMultiplier/Std": 0,
    "Time/Epoch": 493.7783508300781,
    "Time/FPS": 40.504005432128906,
    "Time/Rollout": 388.0379028320313,
    "Time/Total": 47587.7265625,
    "Time/Update": 105.74030303955078,
    "TotalEnvSteps": 2000000,
    "Train/Entropy": 0.8130290508270264,
    "Train/Epoch": 99,
    "Train/KL": 0.003647168166935444,
    "Train/LR": 0,
    "Train/PolicyRatio": 1.00006103515625,
    "Train/PolicyRatio/Max": 1.00006103515625,
    "Train/PolicyRatio/Min": 1.00006103515625,
    "Train/PolicyRatio/Std": 0.00646096421405673,
    "Train/PolicyStd": 0.5456528067588806,
    "Train/StopIter": 40,
    "Value/Adv": -0.2960936725139618,
    "Value/cost": 6.465731143951416,
    "Value/reward": 0.8371739983558655,
    "_runtime": 47589.451599562,
    "_step": 100,
    "_timestamp": 1743374355.03837,
    "_wandb": {
        "runtime": 47589
    }
}