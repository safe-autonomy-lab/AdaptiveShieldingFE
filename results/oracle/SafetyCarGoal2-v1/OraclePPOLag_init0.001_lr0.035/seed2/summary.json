{
    "Loss/Loss_cost_critic": 2.0890183448791504,
    "Loss/Loss_cost_critic/Delta": 0.06256532669067383,
    "Loss/Loss_pi": -0.017015699297189713,
    "Loss/Loss_pi/Delta": 0.01128373108804226,
    "Loss/Loss_reward_critic": 0.03579512611031532,
    "Loss/Loss_reward_critic/Delta": -0.0041732750833034515,
    "Metrics/EpCost": 54.810001373291016,
    "Metrics/EpLen": 1000,
    "Metrics/EpRet": 6.346001148223877,
    "Metrics/LagrangeMultiplier": 3.109595537185669,
    "Metrics/LagrangeMultiplier/Max": 3.109595537185669,
    "Metrics/LagrangeMultiplier/Min": 3.109595537185669,
    "Metrics/LagrangeMultiplier/Std": 0,
    "Time/Epoch": 302.4442443847656,
    "Time/FPS": 66.12789154052734,
    "Time/Rollout": 243.53225708007812,
    "Time/Total": 29100.986328125,
    "Time/Update": 58.91194152832031,
    "TotalEnvSteps": 2000000,
    "Train/Entropy": 0.7427389025688171,
    "Train/Epoch": 99,
    "Train/KL": 0.003716437378898263,
    "Train/LR": 0,
    "Train/PolicyRatio": 1.000146508216858,
    "Train/PolicyRatio/Max": 1.000146508216858,
    "Train/PolicyRatio/Min": 1.000146508216858,
    "Train/PolicyRatio/Std": 0.007004371844232082,
    "Train/PolicyStd": 0.5092477202415466,
    "Train/StopIter": 40,
    "Value/Adv": 0.058497354388237,
    "Value/cost": 5.8002028465271,
    "Value/reward": 0.7236343026161194,
    "_runtime": 29102.538630743,
    "_step": 100,
    "_timestamp": 1743355883.192679,
    "_wandb": {
        "runtime": 29102
    }
}