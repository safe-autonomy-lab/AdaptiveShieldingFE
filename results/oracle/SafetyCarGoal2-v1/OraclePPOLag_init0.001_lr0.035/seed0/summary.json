{
    "Loss/Loss_cost_critic": 2.0975236892700195,
    "Loss/Loss_cost_critic/Delta": -0.06052279472351074,
    "Loss/Loss_pi": -0.016538778319954872,
    "Loss/Loss_pi/Delta": 0.010587068274617197,
    "Loss/Loss_reward_critic": 0.02731765992939472,
    "Loss/Loss_reward_critic/Delta": 0.003440074622631073,
    "Metrics/EpCost": 58.2599983215332,
    "Metrics/EpLen": 1000,
    "Metrics/EpRet": 6.025349140167236,
    "Metrics/LagrangeMultiplier": 3.2160212993621826,
    "Metrics/LagrangeMultiplier/Max": 3.2160212993621826,
    "Metrics/LagrangeMultiplier/Min": 3.2160212993621826,
    "Metrics/LagrangeMultiplier/Std": 0,
    "Time/Epoch": 559.029052734375,
    "Time/FPS": 35.77631759643555,
    "Time/Rollout": 482.375732421875,
    "Time/Total": 45554.3671875,
    "Time/Update": 76.65322875976562,
    "TotalEnvSteps": 2000000,
    "Train/Entropy": 0.7913326025009155,
    "Train/Epoch": 99,
    "Train/KL": 0.0033478778786957264,
    "Train/LR": 0,
    "Train/PolicyRatio": 1.0001012086868286,
    "Train/PolicyRatio/Max": 1.0001012086868286,
    "Train/PolicyRatio/Min": 1.0001012086868286,
    "Train/PolicyRatio/Std": 0.006042188033461571,
    "Train/PolicyStd": 0.5339654088020325,
    "Train/StopIter": 40,
    "Value/Adv": 0.12535229325294495,
    "Value/cost": 5.582252502441406,
    "Value/reward": 0.6179388761520386,
    "_runtime": 45556.201386314,
    "_step": 100,
    "_timestamp": 1743372081.8890345,
    "_wandb": {
        "runtime": 45556
    }
}