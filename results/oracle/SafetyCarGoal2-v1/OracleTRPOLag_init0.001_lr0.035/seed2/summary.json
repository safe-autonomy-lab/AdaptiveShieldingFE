{
    "Loss/Loss_cost_critic": 1.5696791410446167,
    "Loss/Loss_cost_critic/Delta": 0.5642973184585571,
    "Loss/Loss_pi": -0.01744643785059452,
    "Loss/Loss_pi/Delta": -0.0006207842379808426,
    "Loss/Loss_reward_critic": 0.04050419479608536,
    "Loss/Loss_reward_critic/Delta": -0.02550463378429413,
    "Metrics/EpCost": 22.93000030517578,
    "Metrics/EpLen": 1000,
    "Metrics/EpRet": 1.8611990213394165,
    "Metrics/LagrangeMultiplier": 2.468532085418701,
    "Metrics/LagrangeMultiplier/Max": 2.468532085418701,
    "Metrics/LagrangeMultiplier/Min": 2.468532085418701,
    "Metrics/LagrangeMultiplier/Std": 0,
    "Misc/AcceptanceStep": 1,
    "Misc/Alpha": 0.729374885559082,
    "Misc/FinalStepNorm": 0.26578888297080994,
    "Misc/H_inv_g": 0.36440643668174744,
    "Misc/gradient_norm": 0.2502831518650055,
    "Misc/xHx": 0.03759483993053436,
    "Time/Epoch": 552.5051879882812,
    "Time/FPS": 36.19875717163086,
    "Time/Rollout": 537.8485107421875,
    "Time/Total": 44749.6015625,
    "Time/Update": 14.65665054321289,
    "TotalEnvSteps": 2000000,
    "Train/Entropy": 1.2118297815322876,
    "Train/Epoch": 99,
    "Train/KL": 0.0003797619719989598,
    "Train/LR": 0,
    "Train/PolicyRatio": 0.9996953010559082,
    "Train/PolicyRatio/Max": 0.9996953010559082,
    "Train/PolicyRatio/Min": 0.9996953010559082,
    "Train/PolicyRatio/Std": 0.00021545469644479456,
    "Train/PolicyStd": 0.8166764378547668,
    "Train/StopIter": 10,
    "Value/Adv": -9.536742950899681e-09,
    "Value/cost": 1.878364086151123,
    "Value/reward": 0.21640092134475708,
    "_runtime": 44751.170215858,
    "_step": 100,
    "_timestamp": 1743371059.8395922,
    "_wandb": {
        "runtime": 44751
    }
}