{
    "Loss/Loss_cost_critic": 9.426895141601562,
    "Loss/Loss_cost_critic/Delta": -1.275177001953125,
    "Loss/Loss_pi": -0.0028187816496938467,
    "Loss/Loss_pi/Delta": 0.002052843803539872,
    "Loss/Loss_reward_critic": 0.3522984981536865,
    "Loss/Loss_reward_critic/Delta": 0.11834006011486052,
    "Metrics/EpCost": 97.94000244140624,
    "Metrics/EpLen": 500,
    "Metrics/EpRet": 38.40317916870117,
    "Metrics/LagrangeMultiplier": 0.2602226734161377,
    "Metrics/LagrangeMultiplier/Max": 0.2602226734161377,
    "Metrics/LagrangeMultiplier/Min": 0.2602226734161377,
    "Metrics/LagrangeMultiplier/Std": 0,
    "Time/Epoch": 199.5804443359375,
    "Time/FPS": 100.21021270751952,
    "Time/Rollout": 101.07611846923828,
    "Time/Total": 19888.80078125,
    "Time/Update": 98.50423431396484,
    "TotalEnvSteps": 2000000,
    "Train/Entropy": 0.24358104169368744,
    "Train/Epoch": 99,
    "Train/KL": 0.003338082693517208,
    "Train/LR": 0,
    "Train/PolicyRatio": 0.9998319149017334,
    "Train/PolicyRatio/Max": 0.9998319149017334,
    "Train/PolicyRatio/Min": 0.9998319149017334,
    "Train/PolicyRatio/Std": 0.006054536439478397,
    "Train/PolicyStd": 0.3091225028038025,
    "Train/StopIter": 40,
    "Value/Adv": -0.30608034133911133,
    "Value/cost": 18.59226417541504,
    "Value/reward": 7.682452201843262,
    "_runtime": 19890.417026632,
    "_step": 100,
    "_timestamp": 1745045091.4310908,
    "_wandb": {
        "runtime": 19890
    }
}