{
    "Loss/Loss_cost_critic": 4.348851680755615,
    "Loss/Loss_cost_critic/Delta": 0.30228281021118164,
    "Loss/Loss_pi": -0.005844481289386749,
    "Loss/Loss_pi/Delta": 0.001228630542755127,
    "Loss/Loss_reward_critic": 0.2638968229293823,
    "Loss/Loss_reward_critic/Delta": 0.00512772798538208,
    "Metrics/EpCost": 32.20000076293945,
    "Metrics/EpLen": 500,
    "Metrics/EpRet": 32.47102355957031,
    "Metrics/LagrangeMultiplier": 1.6552178859710691,
    "Metrics/LagrangeMultiplier/Max": 1.6552178859710691,
    "Metrics/LagrangeMultiplier/Min": 1.6552178859710691,
    "Metrics/LagrangeMultiplier/Std": 0,
    "Time/Epoch": 150.551513671875,
    "Time/FPS": 132.8448944091797,
    "Time/Rollout": 91.95938873291016,
    "Time/Total": 15309.71875,
    "Time/Update": 58.592063903808594,
    "TotalEnvSteps": 2000000,
    "Train/Entropy": 0.38836878538131714,
    "Train/Epoch": 99,
    "Train/KL": 0.002583813853561878,
    "Train/LR": 0,
    "Train/PolicyRatio": 0.99928617477417,
    "Train/PolicyRatio/Max": 0.99928617477417,
    "Train/PolicyRatio/Min": 0.99928617477417,
    "Train/PolicyRatio/Std": 0.005319814663380384,
    "Train/PolicyStd": 0.3569446802139282,
    "Train/StopIter": 40,
    "Value/Adv": 0.14496839046478271,
    "Value/cost": 7.326278209686279,
    "Value/reward": 6.734799861907959,
    "_runtime": 15310.944229471,
    "_step": 100,
    "_timestamp": 1743321236.122632,
    "_wandb": {
        "runtime": 15310
    }
}