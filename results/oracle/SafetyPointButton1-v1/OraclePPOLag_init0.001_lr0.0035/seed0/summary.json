{
    "Loss/Loss_cost_critic": 1.4838954210281372,
    "Loss/Loss_cost_critic/Delta": -0.4035147428512573,
    "Loss/Loss_pi": -0.006411587819457054,
    "Loss/Loss_pi/Delta": 0.00451265461742878,
    "Loss/Loss_reward_critic": 0.10538402199745178,
    "Loss/Loss_reward_critic/Delta": -0.01476135104894638,
    "Metrics/EpCost": 53.20000076293945,
    "Metrics/EpLen": 1000,
    "Metrics/EpRet": 27.72325897216797,
    "Metrics/LagrangeMultiplier": 0.34547972679138184,
    "Metrics/LagrangeMultiplier/Max": 0.34547972679138184,
    "Metrics/LagrangeMultiplier/Min": 0.34547972679138184,
    "Metrics/LagrangeMultiplier/Std": 0,
    "Time/Epoch": 150.04931640625,
    "Time/FPS": 133.2895050048828,
    "Time/Rollout": 81.1705551147461,
    "Time/Total": 14401.369140625,
    "Time/Update": 68.87870788574219,
    "TotalEnvSteps": 2000000,
    "Train/Entropy": -0.11647246778011322,
    "Train/Epoch": 99,
    "Train/KL": 0.004161275457590818,
    "Train/LR": 0,
    "Train/PolicyRatio": 1.0002411603927612,
    "Train/PolicyRatio/Max": 1.0002411603927612,
    "Train/PolicyRatio/Min": 1.0002411603927612,
    "Train/PolicyRatio/Std": 0.006679549813270569,
    "Train/PolicyStd": 0.21649228036403656,
    "Train/StopIter": 40,
    "Value/Adv": 0.20072780549526217,
    "Value/cost": 7.453617095947266,
    "Value/reward": 2.9384067058563232,
    "_runtime": 14402.974327459,
    "_step": 100,
    "_timestamp": 1745035294.7323878,
    "_wandb": {
        "runtime": 14402
    }
}