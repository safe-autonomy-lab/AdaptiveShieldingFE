{
    "Loss/Loss_cost_critic": 1.8253347873687744,
    "Loss/Loss_cost_critic/Delta": -0.5800726413726807,
    "Loss/Loss_pi": -0.006796840578317642,
    "Loss/Loss_pi/Delta": 0.0030259322375059128,
    "Loss/Loss_reward_critic": 0.10612286627292632,
    "Loss/Loss_reward_critic/Delta": -0.019400253891944885,
    "Metrics/EpCost": 57.2400016784668,
    "Metrics/EpLen": 1000,
    "Metrics/EpRet": 30.661611557006836,
    "Metrics/LagrangeMultiplier": 0.36053159832954407,
    "Metrics/LagrangeMultiplier/Max": 0.36053159832954407,
    "Metrics/LagrangeMultiplier/Min": 0.36053159832954407,
    "Metrics/LagrangeMultiplier/Std": 0,
    "Time/Epoch": 112.2309799194336,
    "Time/FPS": 178.20391845703125,
    "Time/Rollout": 62.61965560913086,
    "Time/Total": 11458.638671875,
    "Time/Update": 49.61128234863281,
    "TotalEnvSteps": 2000000,
    "Train/Entropy": -0.1113293319940567,
    "Train/Epoch": 99,
    "Train/KL": 0.0037473205011338,
    "Train/LR": 0,
    "Train/PolicyRatio": 1.0002073049545288,
    "Train/PolicyRatio/Max": 1.0002073049545288,
    "Train/PolicyRatio/Min": 1.0002073049545288,
    "Train/PolicyRatio/Std": 0.006844164803624153,
    "Train/PolicyStd": 0.2182321697473526,
    "Train/StopIter": 40,
    "Value/Adv": 0.25856906175613403,
    "Value/cost": 7.539947032928467,
    "Value/reward": 3.0651726722717285,
    "_runtime": 11459.820758135,
    "_step": 100,
    "_timestamp": 1745033609.25582,
    "_wandb": {
        "runtime": 11459
    }
}