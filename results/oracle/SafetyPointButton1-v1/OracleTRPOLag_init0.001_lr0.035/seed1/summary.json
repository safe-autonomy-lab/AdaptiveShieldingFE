{
    "Loss/Loss_cost_critic": 1.0613301992416382,
    "Loss/Loss_cost_critic/Delta": -0.37914907932281494,
    "Loss/Loss_pi": -0.015833605080842972,
    "Loss/Loss_pi/Delta": 0.00020037032663822177,
    "Loss/Loss_reward_critic": 0.0604918859899044,
    "Loss/Loss_reward_critic/Delta": -0.00713769719004631,
    "Metrics/EpCost": 20.979999542236328,
    "Metrics/EpLen": 1000,
    "Metrics/EpRet": 5.193490982055664,
    "Metrics/LagrangeMultiplier": 3.0154833793640137,
    "Metrics/LagrangeMultiplier/Max": 3.0154833793640137,
    "Metrics/LagrangeMultiplier/Min": 3.0154833793640137,
    "Metrics/LagrangeMultiplier/Std": 0,
    "Misc/AcceptanceStep": 1,
    "Misc/Alpha": 0.76924067735672,
    "Misc/FinalStepNorm": 0.28874197602272034,
    "Misc/H_inv_g": 0.3753597140312195,
    "Misc/gradient_norm": 0.26947686076164246,
    "Misc/xHx": 0.03379911929368973,
    "Time/Epoch": 113.83926391601562,
    "Time/FPS": 175.68630981445312,
    "Time/Rollout": 93.6387939453125,
    "Time/Total": 11327.134765625,
    "Time/Update": 20.200441360473633,
    "TotalEnvSteps": 2000000,
    "Train/Entropy": 1.1448270082473757,
    "Train/Epoch": 99,
    "Train/KL": 0.00032050584559328854,
    "Train/LR": 0,
    "Train/PolicyRatio": 1.000345230102539,
    "Train/PolicyRatio/Max": 1.000345230102539,
    "Train/PolicyRatio/Min": 1.000345230102539,
    "Train/PolicyRatio/Std": 0.00024405836302321404,
    "Train/PolicyStd": 0.7616139054298401,
    "Train/StopIter": 10,
    "Value/Adv": 9.918212917625624e-09,
    "Value/cost": 2.2049975395202637,
    "Value/reward": 0.4736569225788117,
    "_runtime": 11329.042484482,
    "_step": 100,
    "_timestamp": 1743317255.712563,
    "_wandb": {
        "runtime": 11329
    }
}