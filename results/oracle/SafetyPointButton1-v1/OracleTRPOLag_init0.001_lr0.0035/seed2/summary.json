{
    "Loss/Loss_cost_critic": 2.3164989948272705,
    "Loss/Loss_cost_critic/Delta": -0.53877854347229,
    "Loss/Loss_pi": -0.011672989465296268,
    "Loss/Loss_pi/Delta": 0.0005656052380800247,
    "Loss/Loss_reward_critic": 0.1116114929318428,
    "Loss/Loss_reward_critic/Delta": -0.024407826364040375,
    "Metrics/EpCost": 67.5199966430664,
    "Metrics/EpLen": 1000,
    "Metrics/EpRet": 31.029335021972656,
    "Metrics/LagrangeMultiplier": 0.33674144744873047,
    "Metrics/LagrangeMultiplier/Max": 0.33674144744873047,
    "Metrics/LagrangeMultiplier/Min": 0.33674144744873047,
    "Metrics/LagrangeMultiplier/Std": 0,
    "Misc/AcceptanceStep": 1,
    "Misc/Alpha": 1.1625170707702637,
    "Misc/FinalStepNorm": 0.1724170595407486,
    "Misc/H_inv_g": 0.14831356704235077,
    "Misc/gradient_norm": 0.534972071647644,
    "Misc/xHx": 0.014798952266573906,
    "Time/Epoch": 81.9095458984375,
    "Time/FPS": 244.1717987060547,
    "Time/Rollout": 72.5401382446289,
    "Time/Total": 8196.9208984375,
    "Time/Update": 9.369380950927734,
    "TotalEnvSteps": 2000000,
    "Train/Entropy": 0.6468392014503479,
    "Train/Epoch": 99,
    "Train/KL": 0.0004886156530119479,
    "Train/LR": 0,
    "Train/PolicyRatio": 1.000892996788025,
    "Train/PolicyRatio/Max": 1.000892996788025,
    "Train/PolicyRatio/Min": 1.000892996788025,
    "Train/PolicyRatio/Std": 0.0006314159836620092,
    "Train/PolicyStd": 0.4755280017852783,
    "Train/StopIter": 10,
    "Value/Adv": -7.438659466174613e-09,
    "Value/cost": 7.112326622009277,
    "Value/reward": 3.156900644302368,
    "_runtime": 8198.603398685,
    "_step": 100,
    "_timestamp": 1745011497.4374142,
    "_wandb": {
        "runtime": 8198
    }
}