{
    "Loss/Loss_cost_critic": 0.08161181956529617,
    "Loss/Loss_cost_critic/Delta": -0.2666604444384575,
    "Loss/Loss_pi": -0.0007585211424157023,
    "Loss/Loss_pi/Delta": 0.004289864678867161,
    "Loss/Loss_reward_critic": 0.013010316528379915,
    "Loss/Loss_reward_critic/Delta": -0.0009088506922125816,
    "Metrics/EpCost": 3.660000085830689,
    "Metrics/EpLen": 1000,
    "Metrics/EpRet": -1.762789607048035,
    "Metrics/LagrangeMultiplier": 187.50750732421875,
    "Metrics/LagrangeMultiplier/Max": 187.50750732421875,
    "Metrics/LagrangeMultiplier/Min": 187.50750732421875,
    "Metrics/LagrangeMultiplier/Std": 0,
    "Time/Epoch": 218.78317260742188,
    "Time/FPS": 91.41470336914062,
    "Time/Rollout": 92.76996612548828,
    "Time/Total": 21316.38671875,
    "Time/Update": 126.01311492919922,
    "TotalEnvSteps": 2000000,
    "Train/Entropy": 0.7417546510696411,
    "Train/Epoch": 99,
    "Train/KL": 0.0032726572826504707,
    "Train/LR": 0,
    "Train/PolicyRatio": 1.0003321170806885,
    "Train/PolicyRatio/Max": 1.0003321170806885,
    "Train/PolicyRatio/Min": 1.0003321170806885,
    "Train/PolicyRatio/Std": 0.005360150709748268,
    "Train/PolicyStd": 0.5114404559135437,
    "Train/StopIter": 40,
    "Value/Adv": 0.013199154287576675,
    "Value/cost": 0.1565401256084442,
    "Value/reward": -0.1867019236087799,
    "_runtime": 21317.885715305,
    "_step": 100,
    "_timestamp": 1745044533.5674355,
    "_wandb": {
        "runtime": 21317
    }
}