{
    "Loss/Loss_cost_critic": 0.014418999664485456,
    "Loss/Loss_cost_critic/Delta": -0.12614135909825563,
    "Loss/Loss_pi": -0.0002191524981753901,
    "Loss/Loss_pi/Delta": 0.0032878152997000143,
    "Loss/Loss_reward_critic": 0.010347653180360794,
    "Loss/Loss_reward_critic/Delta": -0.0027597742155194283,
    "Metrics/EpCost": 0.5299999713897705,
    "Metrics/EpLen": 1000,
    "Metrics/EpRet": -2.195833206176758,
    "Metrics/LagrangeMultiplier": 141.16140747070312,
    "Metrics/LagrangeMultiplier/Max": 141.16140747070312,
    "Metrics/LagrangeMultiplier/Min": 141.16140747070312,
    "Metrics/LagrangeMultiplier/Std": 0,
    "Time/Epoch": 186.32757568359375,
    "Time/FPS": 107.3378448486328,
    "Time/Rollout": 86.39812469482422,
    "Time/Total": 18263.369140625,
    "Time/Update": 99.92935180664062,
    "TotalEnvSteps": 2000000,
    "Train/Entropy": 0.5183794498443604,
    "Train/Epoch": 99,
    "Train/KL": 0.003746416419744491,
    "Train/LR": 0,
    "Train/PolicyRatio": 1.0004199743270874,
    "Train/PolicyRatio/Max": 1.0004199743270874,
    "Train/PolicyRatio/Min": 1.0004199743270874,
    "Train/PolicyRatio/Std": 0.005649118218570948,
    "Train/PolicyStd": 0.41404664516448975,
    "Train/StopIter": 40,
    "Value/Adv": -0.12418306618928908,
    "Value/cost": 0.054934002459049225,
    "Value/reward": -0.2214689403772354,
    "_runtime": 18264.559874202,
    "_step": 100,
    "_timestamp": 1745042832.711863,
    "_wandb": {
        "runtime": 18264
    }
}