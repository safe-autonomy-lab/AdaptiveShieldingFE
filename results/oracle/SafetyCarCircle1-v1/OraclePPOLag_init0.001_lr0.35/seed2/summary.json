{
    "Loss/Loss_cost_critic": 0.4531776010990143,
    "Loss/Loss_cost_critic/Delta": 0.2676546722650528,
    "Loss/Loss_pi": -0.0042667752131819725,
    "Loss/Loss_pi/Delta": -0.0013340571895241735,
    "Loss/Loss_reward_critic": 0.04067843779921532,
    "Loss/Loss_reward_critic/Delta": -0.005094178020954132,
    "Metrics/EpCost": 1.350000023841858,
    "Metrics/EpLen": 500,
    "Metrics/EpRet": 7.349178314208984,
    "Metrics/LagrangeMultiplier": 12.051628112792969,
    "Metrics/LagrangeMultiplier/Max": 12.051628112792969,
    "Metrics/LagrangeMultiplier/Min": 12.051628112792969,
    "Metrics/LagrangeMultiplier/Std": 0,
    "Time/Epoch": 156.9490509033203,
    "Time/FPS": 127.4298858642578,
    "Time/Rollout": 97.94197082519533,
    "Time/Total": 14710.5927734375,
    "Time/Update": 59.00703430175781,
    "TotalEnvSteps": 2000000,
    "Train/Entropy": 0.5905848741531372,
    "Train/Epoch": 99,
    "Train/KL": 0.004092906601727009,
    "Train/LR": 0,
    "Train/PolicyRatio": 1.0007238388061523,
    "Train/PolicyRatio/Max": 1.0007238388061523,
    "Train/PolicyRatio/Min": 1.0007238388061523,
    "Train/PolicyRatio/Std": 0.00678878091275692,
    "Train/PolicyStd": 0.43749168515205383,
    "Train/StopIter": 40,
    "Value/Adv": 0.06012772023677826,
    "Value/cost": 0.1955036818981171,
    "Value/reward": 1.670464277267456,
    "_runtime": 14711.988516423,
    "_step": 100,
    "_timestamp": 1745056716.105285,
    "_wandb": {
        "runtime": 14711
    }
}