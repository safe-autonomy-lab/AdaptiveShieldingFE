{
    "Loss/Loss_cost_critic": 2.595486879348755,
    "Loss/Loss_cost_critic/Delta": 1.0603103637695312,
    "Loss/Loss_pi": -0.011060007847845554,
    "Loss/Loss_pi/Delta": -0.002648160792887211,
    "Loss/Loss_reward_critic": 0.09374170750379562,
    "Loss/Loss_reward_critic/Delta": 0.0222056582570076,
    "Metrics/EpCost": 18.280000686645508,
    "Metrics/EpLen": 500,
    "Metrics/EpRet": 13.532888412475586,
    "Metrics/LagrangeMultiplier": 1.3751541376113892,
    "Metrics/LagrangeMultiplier/Max": 1.3751541376113892,
    "Metrics/LagrangeMultiplier/Min": 1.3751541376113892,
    "Metrics/LagrangeMultiplier/Std": 0,
    "Time/Epoch": 161.23301696777344,
    "Time/FPS": 124.04407501220705,
    "Time/Rollout": 96.95528411865234,
    "Time/Total": 15584.74609375,
    "Time/Update": 64.27767181396484,
    "TotalEnvSteps": 2000000,
    "Train/Entropy": 0.5614717602729797,
    "Train/Epoch": 99,
    "Train/KL": 0.003680954221636057,
    "Train/LR": 0,
    "Train/PolicyRatio": 0.999845564365387,
    "Train/PolicyRatio/Max": 0.9998456239700316,
    "Train/PolicyRatio/Min": 0.9998456239700316,
    "Train/PolicyRatio/Std": 0.006891523487865925,
    "Train/PolicyStd": 0.4330354928970337,
    "Train/StopIter": 40,
    "Value/Adv": -0.12433239817619324,
    "Value/cost": 2.359959602355957,
    "Value/reward": 2.9281961917877197,
    "_runtime": 15586.401998012,
    "_step": 100,
    "_timestamp": 1743339891.575096,
    "_wandb": {
        "runtime": 15586
    }
}