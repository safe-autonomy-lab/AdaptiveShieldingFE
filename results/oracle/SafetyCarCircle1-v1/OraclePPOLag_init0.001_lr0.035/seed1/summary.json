{
    "Loss/Loss_cost_critic": 1.4757452011108398,
    "Loss/Loss_cost_critic/Delta": -0.27328383922576904,
    "Loss/Loss_pi": -0.006878168787807226,
    "Loss/Loss_pi/Delta": 0.006558863911777735,
    "Loss/Loss_reward_critic": 0.09662129729986192,
    "Loss/Loss_reward_critic/Delta": 0.01896408200263977,
    "Metrics/EpCost": 11.960000038146973,
    "Metrics/EpLen": 500,
    "Metrics/EpRet": 12.608183860778809,
    "Metrics/LagrangeMultiplier": 1.6853079795837402,
    "Metrics/LagrangeMultiplier/Max": 1.6853079795837402,
    "Metrics/LagrangeMultiplier/Min": 1.6853079795837402,
    "Metrics/LagrangeMultiplier/Std": 0,
    "Time/Epoch": 209.79562377929688,
    "Time/FPS": 95.33087921142578,
    "Time/Rollout": 108.03656005859376,
    "Time/Total": 19421.1171875,
    "Time/Update": 101.75891876220705,
    "TotalEnvSteps": 2000000,
    "Train/Entropy": 0.5105211138725281,
    "Train/Epoch": 99,
    "Train/KL": 0.003494319738820195,
    "Train/LR": 0,
    "Train/PolicyRatio": 0.9992931485176086,
    "Train/PolicyRatio/Max": 0.9992931485176086,
    "Train/PolicyRatio/Min": 0.9992931485176086,
    "Train/PolicyRatio/Std": 0.007191264070570469,
    "Train/PolicyStd": 0.406418889760971,
    "Train/StopIter": 40,
    "Value/Adv": -0.3816033005714417,
    "Value/cost": 1.4180867671966553,
    "Value/reward": 2.6864984035491943,
    "_runtime": 19423.352727902,
    "_step": 100,
    "_timestamp": 1743343748.3007646,
    "_wandb": {
        "runtime": 19423
    }
}