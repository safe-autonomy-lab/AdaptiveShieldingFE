{
    "Loss/Loss_cost_critic": 0.7677872776985168,
    "Loss/Loss_cost_critic/Delta": 0.39561012387275696,
    "Loss/Loss_pi": -0.008736712858080864,
    "Loss/Loss_pi/Delta": 3.023538738489151e-05,
    "Loss/Loss_reward_critic": 0.005157832056283951,
    "Loss/Loss_reward_critic/Delta": -0.0007337029092013836,
    "Metrics/EpCost": 3.0299999713897705,
    "Metrics/EpLen": 500,
    "Metrics/EpRet": 0.3558770716190338,
    "Metrics/LagrangeMultiplier": 104.0251007080078,
    "Metrics/LagrangeMultiplier/Max": 104.0251007080078,
    "Metrics/LagrangeMultiplier/Min": 104.0251007080078,
    "Metrics/LagrangeMultiplier/Std": 0,
    "Time/Epoch": 145.8792724609375,
    "Time/FPS": 137.09967041015625,
    "Time/Rollout": 88.69081115722656,
    "Time/Total": 13823.662109375,
    "Time/Update": 57.18840789794922,
    "TotalEnvSteps": 2000000,
    "Train/Entropy": 0.4805847108364105,
    "Train/Epoch": 99,
    "Train/KL": 0.004977622535079718,
    "Train/LR": 0,
    "Train/PolicyRatio": 1.000369906425476,
    "Train/PolicyRatio/Max": 1.000369906425476,
    "Train/PolicyRatio/Min": 1.000369906425476,
    "Train/PolicyRatio/Std": 0.0082695996388793,
    "Train/PolicyStd": 0.3923662602901459,
    "Train/StopIter": 40,
    "Value/Adv": -0.15966945886611938,
    "Value/cost": 0.4297804236412048,
    "Value/reward": 0.11689448356628418,
    "_runtime": 13825.407392507,
    "_step": 100,
    "_timestamp": 1745056024.9326727,
    "_wandb": {
        "runtime": 13825
    }
}