{
    "Loss/Loss_cost_critic": 1.2557621002197266,
    "Loss/Loss_cost_critic/Delta": 0.17086899280548096,
    "Loss/Loss_pi": -0.0089578777551651,
    "Loss/Loss_pi/Delta": -0.00010962411761283876,
    "Loss/Loss_reward_critic": 0.049805738031864166,
    "Loss/Loss_reward_critic/Delta": 0.005485836416482925,
    "Metrics/EpCost": 27.36000061035156,
    "Metrics/EpLen": 1000,
    "Metrics/EpRet": 6.431380748748779,
    "Metrics/LagrangeMultiplier": 3.108487129211426,
    "Metrics/LagrangeMultiplier/Max": 3.108487129211426,
    "Metrics/LagrangeMultiplier/Min": 3.108487129211426,
    "Metrics/LagrangeMultiplier/Std": 0,
    "Time/Epoch": 574.9271240234375,
    "Time/FPS": 34.787017822265625,
    "Time/Rollout": 438.6524963378906,
    "Time/Total": 57748.24609375,
    "Time/Update": 136.27455139160156,
    "TotalEnvSteps": 2000000,
    "Train/Entropy": 1.0526870489120483,
    "Train/Epoch": 99,
    "Train/KL": 0.003296637674793601,
    "Train/LR": 0,
    "Train/PolicyRatio": 1.0000511407852173,
    "Train/PolicyRatio/Max": 1.0000511407852173,
    "Train/PolicyRatio/Min": 1.0000511407852173,
    "Train/PolicyRatio/Std": 0.00660750363022089,
    "Train/PolicyStd": 0.6940972208976746,
    "Train/StopIter": 40,
    "Value/Adv": -0.38008302450180054,
    "Value/cost": 2.3217849731445312,
    "Value/reward": 0.7406030893325806,
    "_runtime": 57750.577732868,
    "_step": 100,
    "_timestamp": 1743370392.6342351,
    "_wandb": {
        "runtime": 57750
    }
}