{
    "Loss/Loss_cost_critic": 1.3893760442733765,
    "Loss/Loss_cost_critic/Delta": -0.34642696380615234,
    "Loss/Loss_pi": -0.00790944043546915,
    "Loss/Loss_pi/Delta": 0.0053062038496136665,
    "Loss/Loss_reward_critic": 0.053196802735328674,
    "Loss/Loss_reward_critic/Delta": 0.0023494139313697815,
    "Metrics/EpCost": 45.470001220703125,
    "Metrics/EpLen": 1000,
    "Metrics/EpRet": 26.426292419433594,
    "Metrics/LagrangeMultiplier": 0.34603673219680786,
    "Metrics/LagrangeMultiplier/Max": 0.34603673219680786,
    "Metrics/LagrangeMultiplier/Min": 0.34603673219680786,
    "Metrics/LagrangeMultiplier/Std": 0,
    "Time/Epoch": 144.1605682373047,
    "Time/FPS": 138.7342071533203,
    "Time/Rollout": 78.46446228027344,
    "Time/Total": 12670.6640625,
    "Time/Update": 65.69605255126953,
    "TotalEnvSteps": 2000000,
    "Train/Entropy": -0.4767298102378845,
    "Train/Epoch": 99,
    "Train/KL": 0.004486504010856152,
    "Train/LR": 0,
    "Train/PolicyRatio": 1.0008224248886108,
    "Train/PolicyRatio/Max": 1.0008224248886108,
    "Train/PolicyRatio/Min": 1.0008224248886108,
    "Train/PolicyRatio/Std": 0.006989060435444117,
    "Train/PolicyStd": 0.1507018655538559,
    "Train/StopIter": 40,
    "Value/Adv": 0.08961540460586548,
    "Value/cost": 4.793546676635742,
    "Value/reward": 2.8023972511291504,
    "_runtime": 12671.954236879,
    "_step": 100,
    "_timestamp": 1745045115.051858,
    "_wandb": {
        "runtime": 12671
    }
}