{
    "Loss/Loss_cost_critic": 1.8323792219161987,
    "Loss/Loss_cost_critic/Delta": -0.06533598899841309,
    "Loss/Loss_pi": -0.00941228959709406,
    "Loss/Loss_pi/Delta": 0.004964232444763184,
    "Loss/Loss_reward_critic": 0.05859070643782616,
    "Loss/Loss_reward_critic/Delta": 0.011209409683942797,
    "Metrics/EpCost": 50.68000030517578,
    "Metrics/EpLen": 1000,
    "Metrics/EpRet": 28.533266067504883,
    "Metrics/LagrangeMultiplier": 0.33916792273521423,
    "Metrics/LagrangeMultiplier/Max": 0.33916792273521423,
    "Metrics/LagrangeMultiplier/Min": 0.33916792273521423,
    "Metrics/LagrangeMultiplier/Std": 0,
    "Time/Epoch": 179.6288604736328,
    "Time/FPS": 111.34068298339844,
    "Time/Rollout": 82.84595489501953,
    "Time/Total": 15393.736328125,
    "Time/Update": 96.78279876708984,
    "TotalEnvSteps": 2000000,
    "Train/Entropy": -0.53330397605896,
    "Train/Epoch": 99,
    "Train/KL": 0.004415533505380154,
    "Train/LR": 0,
    "Train/PolicyRatio": 1.0000792741775513,
    "Train/PolicyRatio/Max": 1.0000792741775513,
    "Train/PolicyRatio/Min": 1.0000792741775513,
    "Train/PolicyRatio/Std": 0.007073111366480589,
    "Train/PolicyStd": 0.1419762820005417,
    "Train/StopIter": 40,
    "Value/Adv": -0.18327069282531736,
    "Value/cost": 5.403624534606934,
    "Value/reward": 3.2510907649993896,
    "_runtime": 15395.598756932,
    "_step": 100,
    "_timestamp": 1745047839.377514,
    "_wandb": {
        "runtime": 15395
    }
}