{
    "Loss/Loss_cost_critic": 0.06720590591430664,
    "Loss/Loss_cost_critic/Delta": -0.33140677213668823,
    "Loss/Loss_pi": -0.0009417731198482216,
    "Loss/Loss_pi/Delta": 0.008381327439565212,
    "Loss/Loss_reward_critic": 0.0241667702794075,
    "Loss/Loss_reward_critic/Delta": 0.0023070815950632095,
    "Metrics/EpCost": 2.990000009536743,
    "Metrics/EpLen": 1000,
    "Metrics/EpRet": -2.5815186500549316,
    "Metrics/LagrangeMultiplier": 185.5813751220703,
    "Metrics/LagrangeMultiplier/Max": 185.5813751220703,
    "Metrics/LagrangeMultiplier/Min": 185.5813751220703,
    "Metrics/LagrangeMultiplier/Std": 0,
    "Time/Epoch": 182.86119079589844,
    "Time/FPS": 109.37257385253906,
    "Time/Rollout": 82.81649017333984,
    "Time/Total": 15634.435546875,
    "Time/Update": 100.04460906982422,
    "TotalEnvSteps": 2000000,
    "Train/Entropy": 0.4214178323745727,
    "Train/Epoch": 99,
    "Train/KL": 0.0032906036358326674,
    "Train/LR": 0,
    "Train/PolicyRatio": 1.0004206895828247,
    "Train/PolicyRatio/Max": 1.0004206895828247,
    "Train/PolicyRatio/Min": 1.0004206895828247,
    "Train/PolicyRatio/Std": 0.005547826178371906,
    "Train/PolicyStd": 0.3693771958351135,
    "Train/StopIter": 40,
    "Value/Adv": -0.1635049730539322,
    "Value/cost": 0.19438104331493375,
    "Value/reward": -0.16546779870986938,
    "_runtime": 15636.446949995,
    "_step": 100,
    "_timestamp": 1745049004.4181497,
    "_wandb": {
        "runtime": 15636
    }
}