{
    "Loss/Loss_cost_critic": 1.3670485019683838,
    "Loss/Loss_cost_critic/Delta": 0.7724718451499939,
    "Loss/Loss_pi": -0.017262673005461693,
    "Loss/Loss_pi/Delta": 0.0031587518751621246,
    "Loss/Loss_reward_critic": 0.016382232308387756,
    "Loss/Loss_reward_critic/Delta": 0.0007273778319358826,
    "Metrics/EpCost": 14.869999885559082,
    "Metrics/EpLen": 1000,
    "Metrics/EpRet": 1.540321946144104,
    "Metrics/LagrangeMultiplier": 24.589797973632812,
    "Metrics/LagrangeMultiplier/Max": 24.589797973632812,
    "Metrics/LagrangeMultiplier/Min": 24.589797973632812,
    "Metrics/LagrangeMultiplier/Std": 0,
    "Time/Epoch": 104.5821533203125,
    "Time/FPS": 191.2372283935547,
    "Time/Rollout": 50.3277473449707,
    "Time/Total": 9018.380859375,
    "Time/Update": 54.254356384277344,
    "TotalEnvSteps": 2000000,
    "Train/Entropy": 0.6251042485237122,
    "Train/Epoch": 99,
    "Train/KL": 0.00412832573056221,
    "Train/LR": 0,
    "Train/PolicyRatio": 1.0002830028533936,
    "Train/PolicyRatio/Max": 1.0002830028533936,
    "Train/PolicyRatio/Min": 1.0002830028533936,
    "Train/PolicyRatio/Std": 0.006972119677811861,
    "Train/PolicyStd": 0.4521995186805725,
    "Train/StopIter": 40,
    "Value/Adv": 0.02339179813861847,
    "Value/cost": 1.0757888555526731,
    "Value/reward": 0.1658549606800079,
    "_runtime": 9019.329274935,
    "_step": 100,
    "_timestamp": 1745042294.9337802,
    "_wandb": {
        "runtime": 9019
    }
}