{
    "Loss/Loss_cost_critic": 0.25728410482406616,
    "Loss/Loss_cost_critic/Delta": -0.3662748336791992,
    "Loss/Loss_pi": -0.004081448074430227,
    "Loss/Loss_pi/Delta": 0.011688357684761286,
    "Loss/Loss_reward_critic": 0.010795298032462595,
    "Loss/Loss_reward_critic/Delta": -0.004299767315387726,
    "Metrics/EpCost": 5.119999885559082,
    "Metrics/EpLen": 1000,
    "Metrics/EpRet": 0.3771167993545532,
    "Metrics/LagrangeMultiplier": 23.524131774902344,
    "Metrics/LagrangeMultiplier/Max": 23.524131774902344,
    "Metrics/LagrangeMultiplier/Min": 23.524131774902344,
    "Metrics/LagrangeMultiplier/Std": 0,
    "Time/Epoch": 102.46936798095705,
    "Time/FPS": 195.18028259277344,
    "Time/Rollout": 52.149410247802734,
    "Time/Total": 9085.17578125,
    "Time/Update": 50.31990814208984,
    "TotalEnvSteps": 2000000,
    "Train/Entropy": 0.587456226348877,
    "Train/Epoch": 99,
    "Train/KL": 0.0050411163829267025,
    "Train/LR": 0,
    "Train/PolicyRatio": 0.9995890259742736,
    "Train/PolicyRatio/Max": 0.9995890259742736,
    "Train/PolicyRatio/Min": 0.9995890259742736,
    "Train/PolicyRatio/Std": 0.007626400794833899,
    "Train/PolicyStd": 0.437856525182724,
    "Train/StopIter": 40,
    "Value/Adv": 0.18990594148635864,
    "Value/cost": 0.5261415839195251,
    "Value/reward": 0.07185354828834534,
    "_runtime": 9087.027500546,
    "_step": 100,
    "_timestamp": 1745041627.0518486,
    "_wandb": {
        "runtime": 9087
    }
}