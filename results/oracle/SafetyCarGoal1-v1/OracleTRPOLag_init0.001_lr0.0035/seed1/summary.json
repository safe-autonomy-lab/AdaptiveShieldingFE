{
    "Loss/Loss_cost_critic": 1.8257066011428833,
    "Loss/Loss_cost_critic/Delta": -0.29211246967315674,
    "Loss/Loss_pi": -0.012518220581114292,
    "Loss/Loss_pi/Delta": 0.0003537936136126518,
    "Loss/Loss_reward_critic": 0.05968192219734192,
    "Loss/Loss_reward_critic/Delta": 0.012452330440282822,
    "Metrics/EpCost": 51.79999923706055,
    "Metrics/EpLen": 1000,
    "Metrics/EpRet": 30.586509704589844,
    "Metrics/LagrangeMultiplier": 0.3264351189136505,
    "Metrics/LagrangeMultiplier/Max": 0.3264351189136505,
    "Metrics/LagrangeMultiplier/Min": 0.3264351189136505,
    "Metrics/LagrangeMultiplier/Std": 0,
    "Misc/AcceptanceStep": 1,
    "Misc/Alpha": 1.027996063232422,
    "Misc/FinalStepNorm": 0.12171617150306702,
    "Misc/H_inv_g": 0.118401400744915,
    "Misc/gradient_norm": 0.3889695405960083,
    "Misc/xHx": 0.018925480544567108,
    "Time/Epoch": 98.998046875,
    "Time/FPS": 202.0241851806641,
    "Time/Rollout": 83.90013885498047,
    "Time/Total": 9931.3896484375,
    "Time/Update": 15.09788703918457,
    "TotalEnvSteps": 2000000,
    "Train/Entropy": 0.523177444934845,
    "Train/Epoch": 99,
    "Train/KL": 0.0005185452755540609,
    "Train/LR": 0,
    "Train/PolicyRatio": 0.999864101409912,
    "Train/PolicyRatio/Max": 0.999864101409912,
    "Train/PolicyRatio/Min": 0.999864101409912,
    "Train/PolicyRatio/Std": 9.612292342353612e-05,
    "Train/PolicyStd": 0.40971294045448303,
    "Train/StopIter": 10,
    "Value/Adv": 1.907348501362094e-09,
    "Value/cost": 5.3038506507873535,
    "Value/reward": 3.456317663192749,
    "_runtime": 9932.98919555,
    "_step": 100,
    "_timestamp": 1745024659.318463,
    "_wandb": {
        "runtime": 9932
    }
}