{
    "Loss/Loss_cost_critic": 0.8675700426101685,
    "Loss/Loss_cost_critic/Delta": 0.47634437680244446,
    "Loss/Loss_pi": -0.010532818734645844,
    "Loss/Loss_pi/Delta": -0.004797060042619705,
    "Loss/Loss_reward_critic": 0.0044027529656887054,
    "Loss/Loss_reward_critic/Delta": -0.0002542254514992237,
    "Metrics/EpCost": 9.359999656677246,
    "Metrics/EpLen": 1000,
    "Metrics/EpRet": 0.1453985720872879,
    "Metrics/LagrangeMultiplier": 3.1779251098632812,
    "Metrics/LagrangeMultiplier/Max": 3.1779251098632812,
    "Metrics/LagrangeMultiplier/Min": 3.1779251098632812,
    "Metrics/LagrangeMultiplier/Std": 0,
    "Time/Epoch": 181.314208984375,
    "Time/FPS": 110.30575561523438,
    "Time/Rollout": 82.6485824584961,
    "Time/Total": 17940.84375,
    "Time/Update": 98.66553497314452,
    "TotalEnvSteps": 2000000,
    "Train/Entropy": 0.4915509521961212,
    "Train/Epoch": 99,
    "Train/KL": 0.0038331053219735622,
    "Train/LR": 0,
    "Train/PolicyRatio": 1.0008445978164673,
    "Train/PolicyRatio/Max": 1.0008445978164673,
    "Train/PolicyRatio/Min": 1.0008445978164673,
    "Train/PolicyRatio/Std": 0.007415040396153927,
    "Train/PolicyStd": 0.3962815999984741,
    "Train/StopIter": 40,
    "Value/Adv": -0.29504135251045227,
    "Value/cost": 1.8754675388336184,
    "Value/reward": 0.0427035354077816,
    "_runtime": 17942.838734457,
    "_step": 100,
    "_timestamp": 1743323869.9934747,
    "_wandb": {
        "runtime": 17942
    }
}