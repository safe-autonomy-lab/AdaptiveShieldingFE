{
    "Loss/Loss_cost_critic": 0.016734842211008072,
    "Loss/Loss_cost_critic/Delta": 0.004959955811500549,
    "Loss/Loss_pi": -0.0006073563708923757,
    "Loss/Loss_pi/Delta": -7.625500438734889e-05,
    "Loss/Loss_reward_critic": 0.015794172883033752,
    "Loss/Loss_reward_critic/Delta": -0.00733533501625061,
    "Metrics/EpCost": 0.28999999165534973,
    "Metrics/EpLen": 1000,
    "Metrics/EpRet": -0.4254533648490906,
    "Metrics/LagrangeMultiplier": 142.2300262451172,
    "Metrics/LagrangeMultiplier/Max": 142.2300262451172,
    "Metrics/LagrangeMultiplier/Min": 142.2300262451172,
    "Metrics/LagrangeMultiplier/Std": 0,
    "Time/Epoch": 146.57994079589844,
    "Time/FPS": 136.44432067871094,
    "Time/Rollout": 79.81632232666016,
    "Time/Total": 14059.2734375,
    "Time/Update": 66.76355743408203,
    "TotalEnvSteps": 2000000,
    "Train/Entropy": 0.44461044669151306,
    "Train/Epoch": 99,
    "Train/KL": 0.004282183945178986,
    "Train/LR": 0,
    "Train/PolicyRatio": 1.000344157218933,
    "Train/PolicyRatio/Max": 1.000344157218933,
    "Train/PolicyRatio/Min": 1.000344157218933,
    "Train/PolicyRatio/Std": 0.006925271824002266,
    "Train/PolicyStd": 0.3790867626667022,
    "Train/StopIter": 40,
    "Value/Adv": -0.0771002471446991,
    "Value/cost": 0.042946405708789825,
    "Value/reward": -0.06798717379570007,
    "_runtime": 14061.213683066,
    "_step": 100,
    "_timestamp": 1745032405.1575463,
    "_wandb": {
        "runtime": 14061
    }
}