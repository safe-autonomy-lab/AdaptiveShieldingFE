{
    "Loss/Loss_cost_critic": 0.47685444355010986,
    "Loss/Loss_cost_critic/Delta": 0.23013731837272644,
    "Loss/Loss_pi": -0.007034521549940109,
    "Loss/Loss_pi/Delta": -0.0003916989080607891,
    "Loss/Loss_reward_critic": 0.004141263198107481,
    "Loss/Loss_reward_critic/Delta": 0.0008804304525256157,
    "Metrics/EpCost": 6.739999771118164,
    "Metrics/EpLen": 1000,
    "Metrics/EpRet": 0.35040533542633057,
    "Metrics/LagrangeMultiplier": 23.091442108154297,
    "Metrics/LagrangeMultiplier/Max": 23.091442108154297,
    "Metrics/LagrangeMultiplier/Min": 23.091442108154297,
    "Metrics/LagrangeMultiplier/Std": 0,
    "Time/Epoch": 135.73956298828125,
    "Time/FPS": 147.34097290039062,
    "Time/Rollout": 75.6135482788086,
    "Time/Total": 13082.40625,
    "Time/Update": 60.1259651184082,
    "TotalEnvSteps": 2000000,
    "Train/Entropy": 0.5530808568000793,
    "Train/Epoch": 99,
    "Train/KL": 0.00345276715233922,
    "Train/LR": 0,
    "Train/PolicyRatio": 0.99997079372406,
    "Train/PolicyRatio/Max": 0.99997079372406,
    "Train/PolicyRatio/Min": 0.99997079372406,
    "Train/PolicyRatio/Std": 0.006035648752003908,
    "Train/PolicyStd": 0.428036093711853,
    "Train/StopIter": 40,
    "Value/Adv": -0.08698868751525879,
    "Value/cost": 0.7765334844589233,
    "Value/reward": 0.04588537663221359,
    "_runtime": 13083.563695752,
    "_step": 100,
    "_timestamp": 1745027801.930253,
    "_wandb": {
        "runtime": 13083
    }
}